{"id": "_HMPl_5FMF", "forum": "z9SIj-IM7tn", "replyto": "z9SIj-IM7tn", "invitation": "ICLR.cc/2023/Conference/Paper5528/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper5528/Reviewer_aueW", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper5528/Reviewer_aueW", "tcdate": 1666852905236, "tmdate": 1669726737627, "date": 1666852905236, "content.confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.", "content.summary_of_the_paper": "This paper presents an adversarial approach that overcomes this limitation, called competitive PINNs (CPINNs). CPINNs train a discriminator that is rewarded for predicting mistakes the PINN makes. The discriminator and PINN participate in a zero-sum game with the exact PDE solution as an optimal strategy. This approach avoids squaring the large condition numbers of PDE discretizations, which is the likely reason for failures of previous attempts to decrease PINN errors even on benign problems. The numerical results show the accuracy. \n\n", "content.strength_and_weaknesses": "Strength:  By introducing another neural network as the point weight function and following with a min-max optimization, the solution of the PDEs can be more accurate. \n\nWeakness: Introducing a new neural network besides the solution neural network means much more complex for training and becomes much tricker on different tasks. And the weakness is summarized as follows.\n1. there is one similar paper in 2020 as McClenny, Levi, and Ulisses Braga-Neto. \"Self-adaptive physics-informed neural networks using a soft attention mechanism.\" arXiv preprint arXiv:2009.04544 (2020). In that work, they use mask functions for the point weight, and there is no significant difference using a neural network in this work, and the min-max procedure is the same; thus, the novelty is not much. The story is under the structure of the games but still can not change the reality of using a neural network for the point weight adversarial update. No intrinsic difference.\n2. The analysis in section 2.3 is not very firm and too simple, sometimes naive, and the analysis of the neural network is just for a linear mapping which should be at least a two-layer neural network if you really want to explain something. As far as I know, in traditional numerical PDEs, the linear combination of the basis is, of course, a very common and efficient way. And it works well even using the vanilla schemes, such as the finite element method. Further, what really makes the so-called neural PDE different is the approximation by nonlinear neural networks, and it is far not enough to use one linear combination to analyze the neural PDE. There is plenty of work for analyzing PINNs, a direct search may help your analysis.\n3. The results of the experiments are good but also tricky as a new neural network besides the solution neural network is introduced. More neural networks with a min-max optimization will increase the difficulties in training, and it is already complex compared with the traditional numerical solvers. If you can prove in high dimensional problem, the method still achieves good performance, just like Bao et al. in the weak adversarial neural network (Zang, Yaohua, et al. \"Weak adversarial networks for high-dimensional partial differential equations.\" Journal of Computational Physics 411 (2020): 109409.), it is much better. Further, in the experiments, such as nearly all of the l2 error figures, the L2 relative error curve with respect to the iteration is not stable, but the experiments are just stopped at best. See Figure 4; there is still a very large oscillation. And Figure 5 has a big shock and etc. Also, it is hard to determine which one enhanced the performance, the optimizer or the structure, see Table 1. \n4. The terms are a little confusing for those who are not familiar with neural PDEs and may lead misunderstandings. The work is very direct with adversarial updating point weight in the area of Neural PDE, but the terms, such as bets, game, etc., will confuse the readers. A direct statement would make things much easier.\n", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity: Not clear. The work is very direct with adversarial updating point weight in the area of Neural PDE, but the terms, such as bets, game, etc., will confuse the readers. \n\nQuality: Good. But the stop iteration is not natural. See #3 above for the detail.\n\nNovelty: Weak. See #1 above.\n\nReproducibility: Good. The authors provide the code, but the method seems hard to use in other cases for requiring careful training.\n\n", "content.summary_of_the_review": "Based on the weakness, I reject the paper. ", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "z9SIj-IM7tn"}
{"id": "QRbjzpZvHr", "forum": "z9SIj-IM7tn", "replyto": "z9SIj-IM7tn", "invitation": "ICLR.cc/2023/Conference/Paper5528/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper5528/Reviewer_QL5E", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper5528/Reviewer_QL5E", "tcdate": 1665787682361, "tmdate": 1668639714710, "date": 1665787682361, "content.confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.", "content.summary_of_the_paper": "This paper introduce competitive physics-informed networks where two neural networks solve a partial differential equation by playing a zero-sum game. The formulation is built using a weak form. The authors claim that this weak form have smaller condition number. ", "content.strength_and_weaknesses": "Strength: The experiments look strong, and the writing is super clear to understand.\n\nWeakness: Several claims are hand waving, and the reviewer is not convinced. I think if the paper is accepted at this stage, it will make confusion in the community. \n\n**Regards Experiment** The reviewer's first major concern is the relationship of this paper with [1] which also uses the weak formulation to train a PDE solution.  I think an experiment comparing these works is essential (using the same optimization algorithm).\n\nThe paper only includes results comparison with respect to the number of iterations. Comparison with respect to the computation time is also needed. For CPINN introduces a new NN and CGD have a matrix inverse. Further computation cost have been included.\n\n**Regards Mni-max** min-max optimization is hard. The complexity lower bound proposed of minimax optimization has a term K_x K_y [2]. I guess using min-max has the same computational complexity as the original formulation.\n\nTo reduce the condition number of laplace squares, we can still use PINN to do this by considering\nmin_{u_1,u} ||u_1-\\nabla u||^2+||f-\\nabla dot u_1||^2\nto solve Delta u = f. I don't think the minimax formulation is essential.\n\nAt the same time, the paper uses ADAM, which is an adaptive method. The adaptive methods can cancel the condition number. I'm confused by this mismatch of the experiment with the theory claimed. \n\n**Regards the Squared residuals.** Changing the loss into the Sobolev norm also introduces a further matrix A. But [3,4] showed this would only accelerate the training both in experiments and theory for the machine learning algorithms. This paper have considered the theory as [4] includes a machine learning model into the learning objective. Can the authors comment on this?\n\n**Related work [5]** The reviewer thinks the paper is still valuable. [5] proposed a similar trick from the optimization community and figured out the improvement of this method.  I encourage the authors to think about combining the theory in [4] and [5] to figure out the true reason this method has an acceleration. \n\n[1] Yaohua Zang, Gang Bao, Xiaojing Ye, and Haomin Zhou. Weak adversarial networks for high-dimensional partial differential equations. Journal of Computational Physics, 411:109409, 2020\n\n[2] Zhang J, Hong M, Zhang S. On lower iteration complexity bounds for the convex-concave saddle point problems. Mathematical Programming, 2022, 194(1): 901-935.\n\n[3] Son H, Jang J W, Han W J, et al. Sobolev training for the neural network solutions of pdes[J]. arXiv preprint arXiv:2101.08932, 2021.\n\n[4] Lu Y, Blanchet J, Ying L. Sobolev Acceleration and Statistical Optimality for Learning Elliptic Equations via Gradient Descent[J]. arXiv preprint arXiv:2205.07331, 2022.\n\n[5] https://proceedings.neurips.cc/paper/2018/file/08048a9c5630ccb67789a198f35d30ec-Paper.pdf \n\n\n===\n\nThe author's response convinced me this is a worth pursuing direction, I've raised my score. \n", "content.clarity,_quality,_novelty_and_reproducibility": "The writing of this paper is super great. I enjoyed reading this paper. ", "content.summary_of_the_review": "The experiments look strong, and the writing is super clear to understand. Several claims are hand waving, and the reviewer is not convinced. I think if the paper is accepted at this stage, it will make confusion in the community. \n\nI still consider this method have made a huge contribution to the PINN family. I suggest authors to investigate paper [5] in detail to see the benefit of this method.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "z9SIj-IM7tn"}
{"id": "CVFx99xcQk", "forum": "z9SIj-IM7tn", "replyto": "z9SIj-IM7tn", "invitation": "ICLR.cc/2023/Conference/Paper5528/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper5528/Reviewer_1E2V", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper5528/Reviewer_1E2V", "tcdate": 1666584639830, "tmdate": 1666584639830, "date": 1666584639830, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper introduces a new model called CPINN, which is an agent based approach to the machine learning solution of PDEs. CPINN is an adversarial approach where the discriminator and PINN, the existing approach to solve PDEs using neural networks, plays a game in order to improve the solution precision of PDEs. The authors motivate their work by the fact that the existing PINNs approaches fail to generate precise solution. The authors show that the proposed model, CPINN, is well-behaved compared to the original PINN model, from the optimization/training perspective. The authors support their claim using multiple PDE problems.", "content.strength_and_weaknesses": "Strengths:\n1-\tNovelty \n2-\tWell-written\n3-\tExperimental results\n\nWeakness: \nCannot think of any\n", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is very well-written and clear. The idea is novel, to the best of my knowledge. I cannot comment on the reproducibility as I am not sure if enough details are provided for that end.", "content.summary_of_the_review": "I enjoyed reading this paper. Physics informed machine learning is a very important and hot problem and still in its infancy. The authors efforts in improving the performance of existing models for this problem needs to be highly acknowledged and rewarded. The authors were able to motivate their approach and support that using experimental study. Overall, I believe this paper has a high quality and ready for publication. I should only add that I am not fully familiar with the state of the arts in this topic and assumed that the authors reflected it well in the paper.  \n\nOne minor issue: I am curious to see similar plots to that of Figure 1 for other datasets.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "z9SIj-IM7tn"}
{"id": "-sNAPTWPYh", "forum": "z9SIj-IM7tn", "replyto": "z9SIj-IM7tn", "invitation": "ICLR.cc/2023/Conference/Paper5528/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper5528/Reviewer_hCa9", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper5528/Reviewer_hCa9", "tcdate": 1666366912170, "tmdate": 1666366912170, "date": 1666366912170, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper produces more accurate physics-informed neural networks (PINNs) by including adversarial training through a discriminator which is rewarded for predicting PINN errors.", "content.strength_and_weaknesses": "Strengths:\n    â€¢ Claims are supported by reported results.\n    â€¢ Concept is sound and sensible.\n    â€¢ Making PINNs more accurate has good impact for the field.\n    â€¢ Paper is well-written and easy to read and navigate.\n    â€¢ Mathematics is well explained.\n    â€¢ Citations are thorough.\n    â€¢ Tradeoffs between this method and conventional PINNs are discussed.\n\nWeaknesses:\n    â€¢ Figures describing the method are not included, and they would make the method easier to understand in this case.", "content.clarity,_quality,_novelty_and_reproducibility": "The work is well-written and easy to follow. Bolded subheadings are used to create small sections, allowing for quick navigation of the paper. \n\nThe experimental quality is quite high, testing on a variety of problems with good results.\n\nThe novelty of the work is middling but non-trivial, with the addition of a discriminator network to reduce error in the PINN. \n\nReproducibility is possible with hyperparameters and implementational details available in the appendix.\n", "content.summary_of_the_review": "This paper seems to be a solid step forward in the field of physics-based neural networks â€“ a field that has high impact on a number of domains. The paper is generally well-written. The novelty of the work is middling (maybe too straightforward because of the recent popularity of GANs) but non-trivial. ", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "z9SIj-IM7tn"}
{"id": "sFg26mcrx2U", "forum": "zA7hVj3rR19", "replyto": "zA7hVj3rR19", "invitation": "ICLR.cc/2023/Conference/Paper3712/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3712/Reviewer_y1Qy", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3712/Reviewer_y1Qy", "tcdate": 1667488886341, "tmdate": 1667488886341, "date": 1667488886341, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "The paper introduce a novel dataset difficulty metric based on how long humans have to view an image in order to classify it correctly. The authors release the difficulty metrics for ImageNet and ObjectNet datasets as well as distribution of image difficulties in those datasets. The paper also introduce a new metric predicting object difficulty. ", "content.strength_and_weaknesses": "Strength:\n- Novel metric for evaluating image difficulty.\n- Valuable and deep analysis of the difficulty, easy and hard samples of ImageNet and ObjectNet datasets. \n- The analysis of various model performance on the samples of different difficulty\n- Promising results that can help constructing the new datasets for various Computer Vision Tasks\n\nWeaknesses:\n- The process of determining the difficulty of the sample is manual and tedious. The authors did not suggest the way to automate the process for the other datasets. It would be interesting to experiment whether a neural network can learn the sample difficulty function from the labeled data and whether this can be used to automatically select samples for labeling\n- The correlation of the model performance and the sample difficulty is expected but it is not proved whether additional \"hard\" samples would improve the model performance. As shown in the paper many of the \"hard\" samples do contain various degradations (occlusions, blur, bad illumination, etc.) The authors might perform a test training a model on 2 versions of the dataset: with less and more \"hard\" samples and evaluating the performance on a fair large scale test dataset.\n- The work does not introduce the updated version of the dataset and does not elaborate what the optimal distribution of the sample difficulty should be.\n- Some of the plots (Figure 7) are hard to follow, authors can change the format or the quantity of the models on the plot to improve the readability.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is relatively well written and easy to follow. The main idea of the paper is clear and well presented. The practical benefit of the difficulty function and the main claim though is somewhat questionable.", "content.summary_of_the_review": "The paper address the important topic of evaluating the dataset quality and difficulty and mining the hard samples. The authors introduce the way to manually compute the difficulty of the sample based on how ling it takes for a human to classify it. Since the process can not be automated for other tasks and it is not fully proven that more hard samples by introduced metric lead the the better model performance the benefit of the suggested metric is debatable. The additional experiments can prove the main concept and increase the usability of the suggested solution", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zA7hVj3rR19"}
{"id": "JJJ6aIq1Az", "forum": "zA7hVj3rR19", "replyto": "zA7hVj3rR19", "invitation": "ICLR.cc/2023/Conference/Paper3712/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3712/Reviewer_aKwB", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3712/Reviewer_aKwB", "tcdate": 1666619623941, "tmdate": 1667497613684, "date": 1666619623941, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "The authors introduce a behavioral approach for identifying challenging images in large image datasets. They use their method to find thousands of challenging images in ImageNet and ObjectNet, and find that CLIP has to a great extent matched humans on these images. Through further analyses they elaborate on the failures seen by different classes of models. They release their datasets and code for the community to build off.", "content.strength_and_weaknesses": "\nStrengths:\n1. Timely investigation of challenging images for humans, with the goal of using those to drive the development of better models.\n2. The authors introduce a toolkit for mining existing datasets for these challenging images.\n3. A combination of web-based and in-lab experimental validation. Very nice agreement between these experiments.\n\n\n\nWeaknesses:\n\n1. Can these images be used to develop better models of AI or human cognition? There's a forward inference/positive result missing here in my opinion. It's not news that CLIP is a good model, so restating that isn't all that interesting to me. It doesn't look like there's any open challenge for AI revealed in these experiments.\n\n2. Does the introduced method identify challenging images consistently, or are some of these images merely poorly labeled exemplars that humans have trouble categorizing?\n\n3. I think the behavioral method is very complicated. Specifically, giving individuals the ability to make a 50-way classification judgement. We don't know the psychological distances between those categories so it's difficult to say whether or not a preponderance of certain categorical choices could makes it easier/harder to find a given category (i.e., it might be harder to distinguish between species of dogs )\n\n4. Make sure you ref [1] as that is most similar to this work for OOD classification.\n\n5. Measuring difficulty in humans is tough -- I agree that there should be images that are unrecognizable in fast presentations, but these same images should be recognizable with enough time. Otherwise, I am worried that the objects are just mislabeled. What do you think?\n\n6. Figure 7 is really cool but also complicated. Would it be possible to add some additional plots to highlight the insights you describe in the text about SimCLR etc?\n\n7. \"We are of course not the first to carry out such viewing time experiments\" I think you should cite the much longer history of rapid visual classification experiments: [2], [3], [4] to give a sampling of works over the years that investigate performance on natural image databases (ImageNet in the case of [4]) as a function of stimulus exposure time. The goal of these works is to limit viewing time to better interogate visual system mechanisms associated with the \"feedforward\" sweep.\n\n8. I suspect the findings of c-score and Figure 8 could be idiosyncratic for different architectures. For instance, \"This analysis reveals that images that require more viewing time... are predicted by later layers in the network.\" This is consistent with the plethora of studies analogizing ResNets and RNNs, which say that the skip connections enable stronger non-linearities and as a result the ability to process more complicated stimuli. What happens when you try other architectures like the ViT in CLIP?\n\n[1] Geirhos et al. Partial success in closing the gap between human and machine vision. 2021.\n\n[2] Fabre-Thorpe. The Characteristics and Limits of Rapid Visual Categorization. 2011.\n[3] Serre et al. A feedforward architecture accounts for rapid categorization. 2007.\n[4] Eberhardt et al. How Deep is the Feature Analysis underlying Rapid Visual Categorization? 2016.\n", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is very clear and the writing is high quality. The figures are fine, nothing fancy. The work is not very novel, and the results mostly align with Geirhos et al., 2021 who did a similar analysis, but the ability to extract challenge images from any dataset could be important. The results appear to be highly reproducible and I commend the authors for replicating their web-based experiments in the lab.", "content.summary_of_the_review": "I am totally borderline on this. I think the method for curating datasets is important but I have some quibbles about its details (50-way classification potentially introduces issues in the data â€” totally non-ecological). I think some of the analyses are interesting but there's no key finding here I can take to my group to say this is changing the way we think about AI or human vision. I look forward to seeing what the other reviewers say. The work is high quality but the impact of the presented results is what keeps me from recommending acceptance.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.details_of_ethics_concerns": "NA", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zA7hVj3rR19"}
{"id": "4QTwpAhF-Hv", "forum": "zA7hVj3rR19", "replyto": "zA7hVj3rR19", "invitation": "ICLR.cc/2023/Conference/Paper3712/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3712/Reviewer_KToy", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3712/Reviewer_KToy", "tcdate": 1667496728609, "tmdate": 1667496728609, "date": 1667496728609, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "The authors propose to conduct psychophysical experiments using a combination of in-lab and\ncrowdsourced subjects to derive an 'objective' (that is, one decoupled from any particular model)\nmeasure of the distribution of sample-difficulty in two widely-used object recognition datasets,\nImageNet and ObjectNet. This differs from recent work that conducts similar experiments to assay\nthe gap between existing models and humans on OOD benchmarks and derive a benchmark using the\ncollected traits. The authors propose to use 'minimum viewing time needed to recognise an object\nwithin an image' as a proxy for sample difficulty, with an object considered 'recognised' if more\nthan half of participants could classify it. Four presentation times are considered for\ncategorisation, with objects recognisable within 17ms constituting the easiest samples, objects\nrecognisable within 10s constituting the hardest samples. The authors find that ImageNet and\nObjectNet are greatly skewed towards easier samples according to the proposed metric and suggest\nincreasing a representation of harder samples to be an important avenue for future work on creating\nmore robust models. The crowdsourced data is compared the data obtained under controlled lab\nconditions and found to be reasonably-well aligned, with discrepancies mainly occurring at the\nshorter presentation times. The authors show that the proposed measure of difficulty correlates\nwith performance-degradation in a variety of models and furthermore that this measure can be\npredicted to some degree using model-based difficulty measures such as c-score and prediction\ndepth.\n", "content.strength_and_weaknesses": "### Strengths\n- The motivation and its distinction from prior work is clearly established -- while similar\n  undertakings have been conducted before, the paper does explore a novel avenue in attempting to\n  quantify sample difficulty in a way decoupled from any given model via psychophysical trials.\n- The scale of the psychophysical experiments is commendable as is the rigor invested in trying to\ncontrol them and validate those conducted under less-controlled conditions (Mechanical Turk).\n  While the results for easier samples may not be entirely admissible, for the hard samples that\n  are of primary interest the two groups do seem to align reasonably well.\n- Figures are mostly clear and germane, with descriptive captions, though some figures are not\nobvious without reading of said captions (namely, Figure 5 and 7).\n- Discussing limitations in the experimental procedure is not shied away from -- the authors, for\n  instance, identify and concede issues with the shorter presentation times, stemming from \n  the use of crowdsourcing. \n- The authors are able to convincingly show correlation between their psychophysics-derived\n  metric and the performance of neural networks across a wide range of architectures. They make a\n  sound case, consistent with other recent literature, that current benchmark datasets for object\n  recognition are lacking in their ability to capture real-world diversity.\n- The authors show with large-scale experimentation that viewing time can serve as a valid\nmetric for sample difficulty across a variety of architectures.\n- The appendices are in their detailing of experimental procedure and materials and in presentation\n  of additional results.\n\n### Weaknesses\n- There is some important related work missing. Most notably, while the authors cite Geirhos et al.\n2018, they neglect to follow up the follow-up work from 2021 [1] which extends the suite of psychophysical\ntrials and shows a closing gap in the OOD performance of humans and machines. Although I understand\nthe goals of said work and the present work to be complementary (the former aiming to evaluate the\ndifferences in robustness, the latter aiming to devise an 'objective' measurement for sample\ndifficulty), given that the works employ similar methodologies to establish a benchmark with which\nto contrast human vs. machine performance (albeit under different regimes), I think some comparison\nis warranted.\n- As alluded to in the above section, while I understand the rationale behind the design choices\nfor Figure 7, it's not an easy figure to navigate visually. Similarly, Figure 5 is confusing for\nits use of presentation time both as a categoriser and as an axis (though I realise an\nexplanation of this is given in the accompanying caption).\n- The proposed method for evaluating sample difficulty is only obviously applicable to datasets of the same\ntype as ImageNet, that is those that are focused on single objects -- there's no obvious way to extend\nthe procedure to instance segmentation datasets, for instance, in which many objects may be\npresent in a scene and the task goes beyond simple image-level recognition.\n- Much of the introduction reads rather informally rather than as academic prose.\n\n(very minor) gripe: The reference associated with Geirhos et al. 2018 is an older (arxiv) version of the\ntext, not the version published at NeurIPS in 2018\n\n[1] Geirhos R, Narayanappa K, Mitzkus B, Thieringer T, Bethge M, Wichmann FA, Brendel W. Partial\nsuccess in closing the gap between human and machine vision. Advances in Neural Information\nProcessing Systems. 2021 Dec 6;34:23885-99.\n", "content.clarity,_quality,_novelty_and_reproducibility": "While the writing could be shored up in some places (e.g. instances of premature sentence\nfull-stops and abrupt transitions) the paper is generally well-written, with the premise,\nmethodology, and analysis all clearly and succinctly presented. The figures are generally germane and\nwell-constructed, though the grouping by presentation time along two axes in Figure 5 is slightly\nconfusing. Details of the experimental procedures, both psychophysical and computational, are given\nin the main text and expanded upon in the appendices. While on the surface similar to works such as\nGeirhos et al. 2021 [1], the paper adopts similar procedures to pursue the complementary objective\nof evaluating the distribution of sample difficulty within two prominent object-recognition datasets.\n\n[1] Geirhos R, Narayanappa K, Mitzkus B, Thieringer T, Bethge M, Wichmann FA, Brendel W. Partial\nsuccess in closing the gap between human and machine vision. Advances in Neural Information\nProcessing Systems. 2021 Dec 6;34:23885-99.\n", "content.summary_of_the_review": "The paper conducts an impressive array of both psychophysical -- involving human subjects -- and\ncomputational experiments in order to derive an validate an objective measure of sample-difficulty\nfor ImageNet and ObjectNet. While I'm not convinced about the extensibility of the method\nto problems beyond ImageNet-style datasets, the paper addresses and attempts to quantify an\nincreasingly-apparent problem; proposes and empirically justifies, through comprehensive analysis, an\nintuitive proxy metric for the datasets in question (which are among the most-used benchmarks in\nML); provides interesting insights into the datasets in question using the derived metric; is generally\nwell-written (consistently clear and concise); and does well in outlining the procedures for the psychophysical trials\nand addressing the ethics and limitations involved.\n", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zA7hVj3rR19"}
{"id": "13H6v_fJtie", "forum": "zA7hVj3rR19", "replyto": "zA7hVj3rR19", "invitation": "ICLR.cc/2023/Conference/Paper3712/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3712/Reviewer_ZZZd", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3712/Reviewer_ZZZd", "tcdate": 1666894010014, "tmdate": 1666894010014, "date": 1666894010014, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper studies a new way of measuring difficulty of computer vision datasets. The authors propose to use humansâ€™ viewing time as a difficulty measure and show that longer viewing time correlates with difficulty. They also show that the measured difficulty can be computationally modeled with a combination of prediction depth, c-score, and adversarial robustness. Analysis of SOTA models reveals that there exists larger gap on harder images.", "content.strength_and_weaknesses": "Strength\n\n* Paper is very well written and easy to follow. Experiments are well designed and systematically executed. Analyses and questions asked in the paper are thought provoking and high quality.\n* Demonstrated the feasibility of this metric as a difficulty measure and identified key next steps we need to work towards as a community.\n* The proposed approach is much more scalable than gaze tracking and can be potentially adopted by others with low cost.\n\n\nWeakness\n\n* Further discussion on what would be a good way to incorporate this metric intro a new data collection protocol  would be useful; how can researchers plan ahead and target at collecting more harder samples in the beginning?\n* It remains unclear whether viewing time would generalize well and serve as a good difficulty metric for other vision tasks such as optical flow\n\n\nI have a minor question on the study design; a set of words are displayed at the end of the viewing session - what if the viewer is not familiar with certain word and fails to answer it correctly because they do not know how the object looks like, but not because they do not recognize the image? \n", "content.clarity,_quality,_novelty_and_reproducibility": "This is a very well written and high quality work. The idea itself may not be original, but the way the problem was studied and analyzed is novel. Dataset and analysis code is released publicly.", "content.summary_of_the_review": "This paper studies an important problem for the computer vision community. The experiments and analysis are well organized and provides new insights. Given the overall strengths of the paper, I recommend acceptance. ", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zA7hVj3rR19"}
{"id": "qWlH5k5X2ed", "forum": "zAbFj7FpD-C", "replyto": "zAbFj7FpD-C", "invitation": "ICLR.cc/2023/Conference/Paper805/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper805/Reviewer_wnYb", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper805/Reviewer_wnYb", "tcdate": 1667388355787, "tmdate": 1667412154459, "date": 1667388355787, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper provides a new regularization perspective on analyzing why the distribution RL methods perform better than the expectation-based RL methods empirically. By leveraging the decomposition assumption of the action-value distributions, this paper proposes to express the objective function of NeuralFZI as the expected effect and the distributional regularization effect. Based on this decomposition, the author(s) proposed DESPI, which is a variant of the soft policy iteration for distributional entropy regularization. Accordingly, to substantiate DESPI in more practical RL tasks, this paper presents a learning algorithm called DERAC, which performs well in some complex continuous control tasks.", "content.strength_and_weaknesses": "**Strength**\n\n- A new perspective of interpreting distributional RL: This paper aims to answer an important question in the distributional RL literature: why do the distributional RL methods have an empirical advantage over the expectation-based RL methods? This paper proposes to decompose the objective function into an expectation term and an additional regularization term. As far as I know, this perspective of distributional RL is quite novel.\n- This paper is easy to understand for most parts of the paper. \n- The proposed method enjoys one additional flexibility (compared to the standard C51) â€“ the weight of value distribution decomposition for controlling the risk sensitivity. This feature could be useful in practice.\n\n**Weaknesses**\n- There are some concerns regarding the decomposition assumption of $F^{s, a}$ in Eq. (4): Given an arbitrary CDF $F^{s,a}$, it is not always true that the resulting $F_{\\mu}^{s,a}$ is also a valid CDF. This is a critical issue since in the proof of Proposition 3, the cross entropy term in the 4th line of Eq. (19) would not always be well-defined. In other words, to establish Proposition 3, one would need to first show that $\\mu$ is indeed a valid PDF. More justification about this assumption is needed.\n- The novelty of the proposed algorithm: The proposed DERAC method can be viewed as a variant of C51 (for discrete actions) and DSAC (for continuous actions) with a slightly different regularization term. It would be good to clarify and highlight the differences between DSAC and C51/DERAC.\n- Lack of discussion on the experiment results: Several experimental results do not appear very conclusive. \nFor example, regarding the result in Figure 4, can the authors explain why the curve of AC+RE+VE performs well in the environments of humanoid and walker2d (despite the conjecture mentioned by the authors)? \nMoreover, in Section 4.2, it is mentioned that â€œOur empirical result in Figure 3 has provided strong evidence to verify our theoretical results.â€ However, this is not completely clear to me since (i) Theorem 1 suggests â€œconvergence to a global optimumâ€ while Figure 3 can only show convergence to some stationary point, and (ii) the empirical result of DERAC cannot be used to corroborate the theoretical results of DERPI given that DERAC is a learning algorithm while DERPI in Theorem 1 is essentially a planning algorithm.\nSince DERAC is a reinterpretation of C51 (which is a distributional method that also uses KL divergence), it is a bit surprising that the performance of DERAC and C51 are rather different in Figure 2.\n\nAnother thing to mention is about the generality of the analysis: It appears that the analysis (cf. Propositions 1-3) requires specifically choosing the KL-divergence in the objective function. It it not immediately clear whether the analysis indeed capture the essence of distributional RL and can address other popular distributional distance metrics (e.g., Wasserstein distance). While this might not be a true weakness, it would be helpful to have a discussion on this somewhere in the paper.", "content.clarity,_quality,_novelty_and_reproducibility": "- For clarity, quality, and novelty, please see the comments above.\n- For reproducibility, the experiments in this paper are built on the source code of DSAC, and the configuration is provided in the appendix. The experiments shall be reproducible.\n", "content.summary_of_the_review": "Overall this paper tackles an important question in distributional RL from a novel perspective. My main concerns are the critical assumption of the value distribution decomposition mentioned above as well as that the experiments look quite inconclusive and require more explanation.", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "3: reject, not good enough", "paper_forum": "zAbFj7FpD-C"}
{"id": "i6xYlLGci1", "forum": "zAbFj7FpD-C", "replyto": "zAbFj7FpD-C", "invitation": "ICLR.cc/2023/Conference/Paper805/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper805/Reviewer_UayF", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper805/Reviewer_UayF", "tcdate": 1666634126906, "tmdate": 1666634126906, "date": 1666634126906, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper performs an analysis of distributional reinforcement learning using a regularization perspective. Specifically, under the assumption of a particular decomposition of the value distribution, they argue that distributional RL provides a risk-sensitive entropy regularization when approximated via the neural fitted Z-iteration framework (something also introduced in this paper).", "content.strength_and_weaknesses": "# Strengths\nThis paper presents an interesting analysis of distributional RL that can be useful for better understanding its differences with traditional (expectational) RL, and likely lead to better algorithms.\n\n# Weaknesses\n## Clarity\nThe main weakness of this paper is its clarity. There is a lot going on and lots of notation to keep track of (sometimes not presented consistently) which makes it hard to follow. Some points related to clarity below:\n1. What is $\\mu$ in equation (4)? It has not been introduced yet.\n1. In the discussion after equation (4) up to the end of page 3 it's not very clear what $F^{s,a}$ and $F^{s,a}_{\\mu}$ are, how they differ, and what the role of each is. A more elaborate discussion may help address point 1 above.\n1. At the bottom of page 3 it says \"Next, we use $p^{s,a}(x)$ to express the true target probability...\", but then it doesn't seem like $p^{s,a}$ is used again. Should this be $\\mu^{s,a}$?\n1. In the discussion below equation (6) it's interesting and somewhat counterintuitive that estimates at the current $s,a$ are evaluated against the next state-action $s',a'$. It would be nice to have some more discussion, and perhaps even a diagram/figure for better exposing this.\n1. In equation (7), where did the horizon $T$ come from? This is the first time it's been introduced and seems to be in conflict with the discounted and infinite-horizon problem setup that has been introduced thus far.\n1. In equation (8) should the expectation be sampling from $P(\\cdot | s_t, a_t)$ instead of $\\rho^{\\pi}$?\n1. Equation (9) seems to me to be somewhat in conflict with what was presented in equation (6), where estimates at the current $s,a$ are evaluated against the next state-action $s',a'$. The rest of the discussion seems to follow equation (9), but then I'm confused as to how equation (6) (and the discussion following it) fits in.\n1. In equation (9) (and sentence following it) it seems we're in a tabular setting, yet you have $q_{\\theta}$. What is the role of $q_{\\theta}$ in a tabular scenario? What is it approximating and how?\n1. In the paragraph following equation (9) it says \"can normally be obtained via bootstrap estimate $\\mu^{s_{t+1},\\pi_Z(s_{t+1})}$ similar in Eq. 6.\" Can you elaborate on this? It's not clear what is meant by this statement.\n1. In Lemma 1 and Theorem 1 there is an assumption of an upper-bound $M$ on the entropy term. Can this be any constant? From the proof it seems all that is necessary is boundedness, so it would be good to clarify the role of $M$ here. In particular, for finite states and actions the entropy term will always be bounded, so the assumption seems to be only necessary when one or the other is not finite.\n1. More importantly, shouldn't the upper-boundedness assumption be on $f(\\mathcal{H}(\\ldots))$? Otherwise, it seems one can pick $f$ adversarially to make the theorem false.\n1. In Lemma 1, what is the $sd$ subscript in one of the $\\mathcal{T}$s? Should it just be $\\mathcal{T}_d$?\n1. Why are you using a finite horizon $T$ in the statement of Lemma 1? It does not appear to be necessary and is related to the point made above.\n1. Figure 1 is nice, but it's not totally clear what the authors are trying to show there. Providing more details in the caption (or in the main text) would help illustrate how it connects to the paper's analyses.\n1. In the first line of page 7 is the $\\epsilon$ with $\\mathbb{E}[\\epsilon]=0$ the same $\\epsilon$ from equation (4)?\n1. In the line after equation (12) it says \"we consider a particular increasing function $f(\\mathcal{H})$, but there is no $f$ in equation (12).\n1. In the first paragraph of section 4 it says QR-DQN is also evaluated, but then later it seems the authors use IQN, not QR-DQN.\n1. In section 4.1 there is a sentence \"Firstly, it is a fact that the value distribution decomposition... owing to the leverage of target networks.\" It is not clear what is meant by this sentence.\n1. In section 4.1 it says \"demonstrate that C51 algorithm can still achieve similar results _under the cross entropy loss_\", which is a little confusing, since C51 was introduced with a cross entropy loss.\n1. In the first paragraph of section 4.1 there is some discussion using $\\varepsilon$ which is rather confusing:\n    1. Is it same as the $\\epsilon$ used earlier in the paragraph (for the continuous decomposition) or different?\n    1. The same $\\varepsilon$ is used to refer to \"the proportion probability\" _and_ \"the true $\\varepsilon$\", which makes things confusing.\n    1. It appears $\\varepsilon$ is referring to the same $\\epsilon$ object from equation (4), but they are different symbols, which makes things confusing.\n1. In general, I found the first paragraph of section 4.1 really hard to follow. Since it is quite important to the paper's contributions, it needs to be clarified.\n\n## Assumptions\nIn section 3.2 the authors assume that $F^{s,a}$ satisfies ... eqn (4). The rest of the paper's analysis seems to hinge on this assumption, but it is not clear to me how reasonable an assumption it is to make.\n\n## Comparison to related work\nAnother weakness is that it is missing discussion with a very related work:\n* [Clare Lyle, Pablo Samuel Castro, Marc G. Bellemare. A Comparative Analysis of Expected and Distributional Reinforcement Learning. AAAI 2019](https://arxiv.org/abs/1901.11084)\n\nLyle et al. prove that for tabular and linear function approximation, distributional and expectational RL are equivalent; with non-linear approximators distributional and expectational are _different_, but sometimes distributional can hurt performance. This seems to be in contrast with some of the wording in the paper under review, where the authors make statements like (emphasis is mine): \"we illuminate the **superiority** of distributional RL over expectation-based RL.\".\n\n# Minor suggestions\n* Second line of page 2 should read: \"result is based on two analy**tical** components, ... by leverag**ing a** variant of gross...\"\n* Top line of page 5 should say \"risk-neu**t**ral\".\n* In section 3.3 when you introduce _Distribution-Entropy-Regularized Policy Iteration_ you may as well introduce the acronym DERPI (instead of waiting until the next page).\n* Above equation (12) it should say \"**objective** function\", not \"objection function\".\n* Below equation (12) it says \"we use the target value distribution neural network $q_{\\theta^*}$\". Then why not just use $q_{\\theta^*}$ directly in equation (12) to make it clear?\n* In **Environments** in section 4 it says three Atari games were used: Breakout, Seaquest, and Asterix. But it seems Hero is being used instead of Asterix.\n* Please specify what the shaded areas represent in your figures.\n* Please restate lemmas/theorems in the appendix when you present the proofs.", "content.clarity,_quality,_novelty_and_reproducibility": "This paper's results do appear to be novel and significant, modulo the question regarding the decomposition assumption I mentioned above.\n\nThe main issue for me is the clarity, which needs substantial improvement.", "content.summary_of_the_review": "I think this is a nice paper that can be an important contribution to further understanding distributional reinforcement learning and can help advance research in this area. However, there is a fair bit of work to do on the clarity front to make this paper useful for others wishing to build on it.\n\nAs it is, I do not believe this paper is ready for publication yet. However, I do believe the authors have an important contribution to provide, so I would encourage them to work on the clarity of the writing and exposition.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "3: reject, not good enough", "paper_forum": "zAbFj7FpD-C"}
{"id": "g8DIDgI0Ezk", "forum": "zAbFj7FpD-C", "replyto": "zAbFj7FpD-C", "invitation": "ICLR.cc/2023/Conference/Paper805/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper805/Reviewer_8Ekx", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper805/Reviewer_8Ekx", "tcdate": 1667482495134, "tmdate": 1667482495134, "date": 1667482495134, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper investigates an important problem of interpreting why distributional RL outperforms conventional RL. Specifically, the author separates the action value function into the expectation part and regularization part, and attributes the superiority to the regularization part. In addition, the author proposes a new algorithm called DERPI for both tabular and function approximation settings. The experimental results manifest the effectiveness. ", "content.strength_and_weaknesses": "Pros\nThe paper investigates an important problem.\nThe paper provides solid theoretical analysis.\n\nCons\n1. Many assumptions are made to gain the theoretical results, but the author does not explain them clearly. e.g., (1)In Section 3.2, the author assumes the action value function satisfies the expectation decomposition of Eq.(4). However, the author needs to convince us why it is true. It seems proposition 1 tries to do that, but it is still not clear why action value function satisfies the decomposition.\n\n2. The paper is hard to follow. The theoretical derivation is not explained clearly. For example, in proposition 1, why the inf is taken over F_\\mu^{s,a}, also the corresponding prof in Appendix A, what does the â€œ||â€ mean in the first inequality of Eq.(15)?\n\n3. As the title of the article shows, the main idea of this paper is to explain the superiority of distributional RL. But actually, the author only explains distributional RL that uses KL divergence, and the experiments are also only performed with the C51 that is based on KL divergence. So I think the topic of the paper should be further narrowed down , since the results can not represent all the distributional RL algorithms.", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity:  This paper does not present a clear logic, such as why comparing with Maximum Entropy RL, it is not enough to just say that â€œestablishes a bridgeâ€.\n\nQuality: The quality of this paper is overall well.\n\nNovelty: Novel problem\n\nReproducibility: No open source code, only provide other people's code\n", "content.summary_of_the_review": "Generally speaking, this paper aims to address an important problem. However, the paper does not solve the problem very well, since the result can only interpret KL-divengence based distributional RL. In addition, there are also not enough experimental scenarios to support the theoretical results.", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zAbFj7FpD-C"}
{"id": "58JUXEBOHA", "forum": "zAbFj7FpD-C", "replyto": "zAbFj7FpD-C", "invitation": "ICLR.cc/2023/Conference/Paper805/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper805/Reviewer_RieR", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper805/Reviewer_RieR", "tcdate": 1666675033581, "tmdate": 1666675033581, "date": 1666675033581, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "his paper addresses the lack of theoretical analysis on why distributional RL works so well and approaches it from the framework of risk-sensitive entropy regularization. It introduces an entropy term in the distributional bellman update which is different from that of conventional MaxEnt frameworks, as it is an entropy of the value-distribution and is state-action-wise rather than just state-wise. \n", "content.strength_and_weaknesses": "Strengths:\n- This paper studies an important topic in distributional RL, by looking at where the superior performance of distributional RL algorithms comes from. It further presents a new framework by incorporating an entropy term of the value-distribution itself (as opposed to the policy entropy) into the Q-value estimation. Furthermore, it retrofits the analysis into the policy iteration and policy evaluation frameworks, which is a familiar theoretical framework. \n- The proposed entropy regularization term is compatible with existing distributional RL algorithms, in particular, the quantile based ones and for both discrete/continous control. \n\nWeaknesses:\n- The theoretical contributions, while interesting are performed on a KL divergence as a distance measure between distributional value-estimates. While the authors acknowledge this is done because Wasserstein distance is less manageable in this theoretical framework, the KL divergence is non-expanding while most state-of-the-art distributional RL papers have moved to contractive distance measures such as Wasserstein or MMD. This discrepancy would seem to lessen the contribution of this paper. \n- The experimental results are not convincing beyond to study the effects of regularizing the update using the proposed DERAC algorithm. The DSAC and C51 comparisons use \"vanilla entropy regularization\" and no regularization and outperfoms DERAC on a majority of tasks. I understand the authors state the empircal results are to corroborate the theoretical results and not necessarily to perform well against existing algorithms, but then it seems there should be additional/different experiments analyzing how exactly the it converges to the optimal risk-sensitive policy. \n- The experiments given in Figure 4. are confusing in terms of drawing conclusions, since they combine two different frameworks for RL. Notably, it is unclear how VE and RE tradeoff against one another.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper studies an important topic in RL, however, the writing lacks some clarity. In particular the italics in many places makes it hard to read at times. The paper is original and may have impact if the empirical validation could be shown. ", "content.summary_of_the_review": "I think this paper requires additional polish and refinement, in particular some empirical demonstrations of the usefulness of the theoretical analyses made. I would lean towards rejecting.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "3: reject, not good enough", "paper_forum": "zAbFj7FpD-C"}
{"id": "wCX5q24DuCt", "forum": "zaEiQ2dgLv", "replyto": "zaEiQ2dgLv", "invitation": "ICLR.cc/2023/Conference/Paper2441/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2441/Reviewer_MBeM", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2441/Reviewer_MBeM", "tcdate": 1666411416113, "tmdate": 1666619421399, "date": 1666411416113, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper proposes a new approach for feature selection, which composes of two components: (1) A feature subset sampler, which learns the distribution of important feature subsets; and (2) a meta-learning based weight generator that quickly constructs a fully connected deep layer for any sampled subset. The method is demonstrated on two datasets. The empirical result is generally positive.", "content.strength_and_weaknesses": "Strength: The approach is quite interesting and the result seems positive. The paper is clearly written.\n\nWeakness:\n1. The paper is not well motivated. \n-- For example, the criticism for embedding methods is that \"they all focus on feature scoring, but the greedily chosen features with high scores are usually not the optimal combination\". I do not agree with this. \n\n-- First, all neural networks are considered (embedding) feature extractors, and their features are learned optimally with backpropagation, which is not a greedy method at all. \n\n-- Second, there is no guarantee that the proposed method selects optimal features either. As far as I understand, any subset selection method is just a special case of an embedding layer with output dim = input dim and zero weights given to unimportant features. What would be the value added of making these weights exactly zero?\n\n2. The empirical result is not very convincing. \n-- What is preventing us from learning an end to end neural network to predict given all features? 20000/5000 features are not prohibitively large numbers of features. Maybe such naive approach would perform worse than the proposed method in the end, but the authors should at least try to include such a simple baseline to demonstrate that these datasets truly need feature selection to perform well.\n\n-- Why do we presume that the optimal subset has exactly 50 features? I think there should be a separate study conducted to verify this number. For example, will MetaFE still perform the best when the subset size is larger? Would there be scalability issues?\n\n-- Evaluating the ranking accuracy is a fair approach to understand the optimality of the selected features. However, it seems that the ranking accuracy is quite bad on sample subsets drawn from the converged sampling distribution. I'm not fully convinced that the reason for this is necessarily \"hard to distinguish among good subsets precisely\". Perhaps one way to verify this exactly is to construct a synthetic dataset with many duplicated features and observe if MetaFE can recover one unique copy of each feature.", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity: The manuscript has quite a number of typos. For example: \"Converaged\" , \"Giseete dataset\", missing x-axis label in Fig. 4, etc. Some notations are not defined properly. For example $\\mathbf{I}_i$ was not defined before its first occurrence in Eq (3). It is also confusing because $i$ was also used to imply indices in the subset. Idea is overall clear, but background review could be more comprehensive.\n\nQuality: Overall the methodology seems sound. I have a few questions/suggestions:\n\n-- Can the author explain the formulation in Eq.(3)? I believe random sampling without replacement will result in a multivariate hypergeometric distribution, whose pmf doesn't look like what you described. \n\n-- The author should consider including other prediction benchmarks without feature selection.\n\n-- Please provide standard deviations for the reported results.\n\n-- I am curious, what might have caused the sudden spike in performance right after pre-training?\n\n-- Using two different y-axes for random and converged on the same plot (Fig. 5) is very misleading. Please use the same y-axis to plot these results. They are not that far apart in scales.\n\n-- Since the proposed method has no theoretical result to back up its claim, I would generally expect more extensive empirical results. Demonstrating on two (heavily down-sampled) datasets, in my opinion, is quite insufficient.\n\nNovelty: The approach is novel and quite intriguing.\n\nReproducibility: The code is provided. I did not try to run it, but I'm convinced that the results can be reproduced.\n\n\n", "content.summary_of_the_review": "Overall, I would recommend a rejection. As stated above, given that this is an empirical work, I believe the reported result is insufficient. The motivation also failed to convince me that there is a practical need for the proposed method.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "3: reject, not good enough", "paper_forum": "zaEiQ2dgLv"}
{"id": "f3udTp91rgT", "forum": "zaEiQ2dgLv", "replyto": "zaEiQ2dgLv", "invitation": "ICLR.cc/2023/Conference/Paper2441/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2441/Reviewer_z1i8", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2441/Reviewer_z1i8", "tcdate": 1667063571932, "tmdate": 1667063571932, "date": 1667063571932, "content.confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper tackles feature selection problem by using meta-learning. They propose to transform the discrete search problem into continuous one and make use of meta learning to evaluate subsets without retraining. They parameterize the search space and apply gradient-based meta-learning in order to effectively reduce the search difficulties. The experimental results show that the proposed method outperforms many of the existing feature selection methodologies.", "content.strength_and_weaknesses": "Strength\n- Paper is well written and easy to understand\n- The problem is important and applying meta-learning to solve the problem seems appropriate.\n- The empirical results are favorable, covering wide variety of existing baselines.\n\nWeaknesses\n- The authors only use two datasets for evaluation, which is quite limiting. I suggest the authors to use more datasets to properly assess the efficacy of their method.\n- The gap from the baselines are quite marginal, and all the experimental evaluation lacks confidence interval. So one cannot say that the evaluation results are statistically significant.", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity, quality, and novelty of the paper is satisfactory. They also provide the code", "content.summary_of_the_review": "In summary, I think the paper tackles the important problem of feature selection, also the method seems appealing as well. However, evaluations are a bit limited, so I encourage the authors to evaluate on more datasets and run all the baselines multiple times to judge the statistical significance.\n\nOverall, I think the strength outweigh the weaknesses, so I recommend weak accept.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zaEiQ2dgLv"}
{"id": "dkor_LxoGe", "forum": "zaEiQ2dgLv", "replyto": "zaEiQ2dgLv", "invitation": "ICLR.cc/2023/Conference/Paper2441/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2441/Reviewer_3nfV", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2441/Reviewer_3nfV", "tcdate": 1666460407199, "tmdate": 1666460407199, "date": 1666460407199, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "The authors address a challenging and important problem of feature selection. The new approach is a wrapper-type method that relies on meta-learning to select the best subset of features for supervised learning. The idea is to transform the large discrete search space into a relaxed continuous space and use gradient descent to find the optimal subset for classification/regression. ", "content.strength_and_weaknesses": "The problem is well-studied but still important for the community. The English level is satisfactory. The method itself seems novel, and the authors propose a way to save computational time by exploiting feature correlation and training sharing weights for models that are trained on the same or similar features. The method is quite intuitive, and the continuous relaxation was already demonstrated effective by other works for feature selection, for example:\nâ€œConcrete Autoencodersâ€ or â€œFeature Selection Using Stochastic Gatesâ€.\n\nSome of the sections in the paper do not read well and are hard to follow. \nThe experimental evaluation is quite poor, the authors only apply the method to two binary data sets (one of them is half synthetic- GISETTE). Also, several leading feature selection baselines are missing.  It is really hard to judge the quality of the approach without additional experiments. The runtime improvements seem promising, but an ablation study is missing from their experiments.\n\n\nIn the following, I detail my comments point by point:\nP1) The authors mention in the introduction that they compare to SOTA in FS, this is not correct, several leading NN baselines are left out, for example:\\\\\n[1] Lemhadri et al. Lassonet: Neural networks with feature sparsity\n[2] Yamada et al. Feature Selection using stochastic gates, 2020\n[3] Balin et al .Concrete autoencoders: Differentiable feature selection and reconstruction\n[4] Singh et al. Fsnet: Feature selection network on high-dimensional biological data\n\nP2) Also, experimenting with two datasets is not considered extensive.\n\nP3) Wrong use of citation style, embed the names in the sentences or use brackets.\n\nP4)Saying that the selection results of filter and embedding method is less effective is wrong and misleading the reader. There are many settings where filter methods excel and save computational time. Furthermore, embedding methods can work with strong NN models and lead to SOTA results.\nConceptually wrapper methods can outperform them, but this might require an unfeasible amount of training time.\n\nP5)Problem 2: an model-> a model\n\nP6) GISETTE is a semi-synthetic data created for the NEURIP 2003 challenge, with most of the features being a nuisance, created artificially. The authors donâ€™t even mention this.\n\nP7) Why do you only select 10K samples for baselines in the Shopping data? And use the full data for your method? This seems unfair.\n\n\nP8) We only select 50 features in experimentsâ€¦.??? What does this sentence mean?\n\n\nP9) You evaluate precision-recall and F1, but you donâ€™t mention what? Namely does can also be evaluated in terms of the ability to identify informative features in GISSETTE (where the set is known). I assume you mean for binary classification, so what threshold do you use to set precision-recall?  \n\nP10) We turn the hyperparameters? Do you mean tune? Also, how do you tune them for all baselines? This is not explained.\n\nP11) The network used is quite narrow and shallow, nowadays theory and practice indicate we need to use wider and deeper models.\n\nP12) Section 5.3 is not clear. For example, â€œwe sample 100 different subsets..â€ of what? I can try to guess what this means, but a paper should be clearly written for readers.\n\nStrong NN FS methods are missing in the related work and evaluations [1]-[4] above\n\n", "content.clarity,_quality,_novelty_and_reproducibility": "The introduction and problem statement are clear, the paper does provide some novelty in the two components proposed by the authors.\n \nThe experimental part and results are not well described, and some details are hard to understand. This would make reproducibility limited.\n", "content.summary_of_the_review": "Overall the authors present a new method for an important problem. They present two components that should reduce the computational effort when using wrapper methods for FS. However, a large portion of the paper is not written in a clear way, and the experiments only focus on two binary datasets. One of them is semi-synthetic. Based on such a small evaluation, I canâ€™t recommend accepting the paper.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "3: reject, not good enough", "paper_forum": "zaEiQ2dgLv"}
{"id": "dITOfJEIvwb", "forum": "zaEiQ2dgLv", "replyto": "zaEiQ2dgLv", "invitation": "ICLR.cc/2023/Conference/Paper2441/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2441/Reviewer_joqh", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2441/Reviewer_joqh", "tcdate": 1667538626449, "tmdate": 1667538626449, "date": 1667538626449, "content.confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.", "content.summary_of_the_paper": "This paper proposes a meta-learning-based feature selection framework that aims to select effective features for machine learning tasks. Specifically, this wrapper framework consists of two components, i.e., Feature Subset Sampler (FSS) which optimizes the discrete search space in a continuous way, and Meta Feature Estimator (MetaFE) which alleviates the cost of re-training machine learning models.", "content.strength_and_weaknesses": "Strengths:\n1. The research problem is important and the idea of MetaFE is meaningful. Wrapper is one of the most widely used strategies in feature selection problems. The major challenge is the repeated and redundant training of the machine learning models. The proposed MetaFE tackle the re-training issue with meta-learning. It could be especially useful for big data.\n2. The FSS transforms an exponential combinatorial optimization problem into a continuous optimization problem, where most existing optimizers in deep learning can be directly adopted. This provides a new perspective for combinatorial optimization.\n\nWeaknesses:\n1. The manuscript is not well polished. There exist many grammar errors, e.g., 'study the purchasing preferences of different peoples', 'construct the usersâ€™ profilingAllegue et al.', 'employing gradient-based method to optimizing the probability distribution'.\n2. The correlation between features is ignored, which is one of the most important factors in feature selection problems. Essentially, in this paper, each feature is independently quantified by an importance number $c$. Feature selection needs a joint distribution of all features, instead of one distribution for each feature.\n3. The proposed method can not decide the number of selected features. Besides, there is a lack of analysis of the selected feature number.", "content.clarity,_quality,_novelty_and_reproducibility": "The logic is clear, but the presentation is not well-polished. Some ideas are novel, but the framework has big flaws. There seems no big issue with reproducibility.", "content.summary_of_the_review": "This paper proposed a wrapper framework to solve feature selection problems. The idea of Feature Subset Sampler (FSS) optimizes the discrete space in a continuous way, and the Meta Feature Estimator (MetaFE) avoids the re-training problem. However, the paper is not well polished, the framework ignores feature-feature correlation, and it lacks solutions to deciding selection feature numbers.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zaEiQ2dgLv"}
{"id": "g1K5Zw0Xg3-", "forum": "zaq4LV55xHl", "replyto": "zaq4LV55xHl", "invitation": "ICLR.cc/2023/Conference/Paper6062/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6062/Reviewer_nMMN", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6062/Reviewer_nMMN", "tcdate": 1666453705627, "tmdate": 1669565076319, "date": 1666453705627, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "The paper describes 1) five antibody prediction benchmark tasks, and 2)  two loss functions for pre-training antibody language proteins to incorporate the evolutionary relationship of antibodies during pre-training. ", "content.strength_and_weaknesses": "## Strengths\n* I am not aware of an existing benchmark specifically for antibodies\n* The described loss functions for incorporating the evolutionary relationship of antibodies during pre-training is interesting and new as far as I know\n\n## Weaknesses\n* The paper is not written clearly enough. The lack of technical details, unclear definitions such as \"Task specificity\", and spelling errors make it hard to understand the paper.\n* Performance improvements are overall small\n* The benchmark contains only five tasks, train/test splits are not justified, and it is unclear if it will be open-sourced. It also does not allow splitting datasets in alternative ways, e.g. by varying the size of the training set or distance to a wildtype sequence.\n\n1) The definition of \"task specificity\" is unclear and needs to be assessed quantitatively. As a consequence, the conclusion that the proposed loss functions improve performance most on the \"most specific\" tasks is vague.\n\n2) Please describe the \"Evolution-aware antibody pretraining method\" more formally by using equations. Phrases such as \"The model is made to distinguish the ancestor germline of the antibody by capturing the shared features\" are insufficient for understanding the necessary technical details to reimplement the loss function.\n\n3) Please correct spelling and grammatical errors throughout the paper.\n\n4) Please describe how and which hyper-parameters of the proposed model and baseline models were tuned?\n\n5) Please describe how models were fine-tuned and if they were all fine-tuned in the same way.\n\n6) Please compare the number of parameters of baseline models and EATLM (w/o AGP, w/o MPP, AGP & MPP) in table 1. Performance improvements can be due to different numbers of parameters rather than differences in the loss function.\n\n7) Please justify how datasets were split into train/test/eval splits. Sequences of the train and test set can be very similar if, e.g., datasets are split randomly. What does \"training/validation/test split of 15,128/3,242/3,242\", for example, mean?\n\n8) The benchmark lacks regression tasks to assess the performance of, e.g., continuous binding affinities (10.48550/arXiv.2210.02881).\n\n9) Please cite Li et al (10.48550/arXiv.2210.02881) in the related work section, who recently proposed an antibody benchmark with two tasks.\n\n10) Please describe whether benchmark datasets and baseline models will be open-sourced\n\n11) Table 2: Please separate metrics of different tasks by vertical lines. It is hard to follow which metrics belong to which tasks.\n\n12) Figure 3: The caption is unclear. Does it show a confusion matrix of model predictions vs. ground-truth labels? The performance of which model is shown? How do per-class performances vary across models? Which class is hardest to predict?\n\n13) Figure 4: Also quantify performances by reporting the AUC and alternative ranking metrics such as Spearman's R or NDCG score.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is not written clearly enough, lacks technical details, and contains many spelling error. It is unclear if the proposed benchmark and methods will be open-sourced.", "content.summary_of_the_review": "I suggest rejecting the paper since it is not written clearly enough and lacks technical details, which make it hard to understand the proposed methodology and assess benchmark results.", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zaq4LV55xHl"}
{"id": "DKa3UYb7UJH", "forum": "zaq4LV55xHl", "replyto": "zaq4LV55xHl", "invitation": "ICLR.cc/2023/Conference/Paper6062/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6062/Reviewer_UNrF", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6062/Reviewer_UNrF", "tcdate": 1666575523513, "tmdate": 1666575523513, "date": 1666575523513, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper provides a comprehensive analysis of Pre-trained Protein Language Models (PPLM) and specific Pre-trained Antibody Language Models on the predictions of different antibody tasks and introduces a new pre-trained method that better utilizes antibody-specific information to achieve a pre-trained antibody language model.", "content.strength_and_weaknesses": "Strength:\n  - This paper is really well-written and easy to follow. The authors provide essential biological and technical backgrounds and clearly state the status, problems, methods, and empirical results.\n  - The problem it tries to solve is important, and the authors provide great insights into this problem.\n  - The provided benchmark could be helpful for future studies.\n\nWeaknesses:\n  - Besides the analysis and insights, the contribution may not be significant enough.\n  - From the modeling perspective, this paper just introduced two new training targets besides MLM that leads to slightly better performance compared to baselines such as *Ablang-H*.\n  - From the benchmark perspective, providing new datasets or incorporating more existing datasets would make this contribution much more significant. \n\n", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity: Great\n\nQuality: Good\n\nNovelty: Good\n\nReproducibility: Easy to reproduce.", "content.summary_of_the_review": "Overall, this paper is of high quality. Considering its technical novelty and empirical performance, I would recommend a weak acceptance.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zaq4LV55xHl"}
{"id": "ARC1sind0m", "forum": "zaq4LV55xHl", "replyto": "zaq4LV55xHl", "invitation": "ICLR.cc/2023/Conference/Paper6062/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6062/Reviewer_rBr6", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6062/Reviewer_rBr6", "tcdate": 1666570905226, "tmdate": 1666570905226, "date": 1666570905226, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper introduces a first-of-its-kind suite of benchmarking tasks for antibody-specific language models and provides some interesting observations about the behavior of general protein models and antibody-specific models on these tasks. It also introduces a new antibody-specific pretraining objective based on the unique evolutionary process of antibodies. \n", "content.strength_and_weaknesses": "=strengths=\nImportant application\nWell written\nProvides a first-of-its kind set of benchmarks for antibody ML\nContributes a new interesting antibody-specific LM model\n\n=Weaknesses=\nSome of the tasks in the benchmark are based on small datasets, such that reliably computing differences between ML systems may be difficult.\nThe covid-19 antibody discovery experiments seem to be a bit forced (see below).\n", "content.clarity,_quality,_novelty_and_reproducibility": "I really appreciated how the paper was written. It provides lots of basic background information on antibodies and discusses these complex topics well. I also really appreciated how much of the exposition was structured in terms of whether tasks are antibody-specific or more general to proteins.\n\nIn general, I am a big supporter of papers that contribute new benchmarking setups. These can be used to drive methods research for years. This paper appears to be the first setup for antibody-specific benchmarking.\n", "content.summary_of_the_review": "The paper introduces (1) a new set of benchmarking tasks, (2) benchmarks a number of models from recent papers, and (3) introduces a new antibody-specific model. I feel that (1) and (2) should be adequate for acceptance. A paper that introduces a new benchmark shouldn't be required to introduce a novel model that achieves SOTA on this benchmark. However, it appears that (3) performs slightly better than prior work.\n\nThe EATLM model is interesting. It adds two new modeling ideas on top of a baseline non-antibody model. It would have been helpful to provide an ablation that shows how much each of these contributes.\n\nOverall, the performance improvement from the proposed EATLM model is positive, but small. It was hard for me to tell if it was actually significant. How did you obtain the error bars in Table 2? I'm concerned that the test sets are small, yet the error bars are small. I recommend obtaining error bars using bootstrap sampling on the test set.  Similarly, in Fig 4 the y axis is small. How do we know that the differences between the lines aren't just due to chance?\n\nFig 5 seems like a basic sanity check, not a groundbreaking result. Couldn't you achieve something similar, for example, by doing UMAP on basic sequence alignment distances between pairs of sequences in the dataset?\n\nI didn't fully understand the 'Antibody Discovery' section, as this is far outside of my expertise area. As far as I understand, a classifier was trained on a dataset containing functional  and non-functional antibodies against covid. Then, this model was used to screen a list of candidate antibodies. The top-ranked ones were then labeled as true-positives simply if they have high sequence identity to true known positives. Wouldn't any sort of nearest-neighbor classifier be guaranteed to get extremely high performance on this task, by construction? I don't understand why the results are impressive.\n\n\nFine tuning language models for downstream tasks is quite challenging, as there are tons of design choices and hyper-parameters. How do you know that what you did provides a fair comparison across models? Is it a standard approach?\n\n", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zaq4LV55xHl"}
{"id": "5RgMdOh14H", "forum": "zaq4LV55xHl", "replyto": "zaq4LV55xHl", "invitation": "ICLR.cc/2023/Conference/Paper6062/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6062/Reviewer_5gxi", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6062/Reviewer_5gxi", "tcdate": 1667138925100, "tmdate": 1669110383353, "date": 1667138925100, "content.confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.", "content.summary_of_the_paper": "This paper studies the different pre-training models for the antibody understanding tasks, propose new methods with biological information for pre-training, and a new antibody understanding benchmark is created. With different study experiments, the authors conclude several observations from different perspectives. ", "content.strength_and_weaknesses": "Strength:\n1. The authors study the antibody understanding tasks, where antibody is the main and crucial element in drug discovery. The authors propose a new benchmark for the antibody understanding tasks, which contain four specific applications. \n2. The authors propose new biological information involved antibody pre-training methods, which improve the understanding of antibody. \n3. The authors study different pre-training models for antibody and they have several conclusions. \n4. The paper is clear and easy to follow. \n\nWeaknesses:\n1. The authors described about the evolution information about the antibody. In their words, the antibody mutation is targeted at the specific objectives, for example to target on the specific antigen. This is somehow questionable, which is a result driven conclusion. Indeed, protein is also randomly mutated, while the last kept ones have specific structures, functions and so on. The differences between antibody mutation and protein mutation is hard to be convinced. \n2. The authors propose two new biological information (evolution) based pre-training objectives, which are actually straightforward. Though they are reasonable, as far as I see, the results are hard to say that these two are effective enough. In terms of these pre-training, different reasons may cause the performance change. I would like the authors to provide more details about the pre-training. For example, how to evaluate the pre-training performances. Indeed, the current ways are like multi-task pre-training. This is a little not enough. \n3. As for the created benchmark, one question is about the data, the authors mentioned the different specificities of these antibodies. I feel good about this, but the datasets seem not be so good enough. The first two tasks are from the same dataset, also the first affinity prediction is much like the last lack, only specific to covid. Besides, the performances on some tasks are already 0.8-0.9, which seem to be somehow good enough. That's what doubted me about the importance of these tasks. ", "content.clarity,_quality,_novelty_and_reproducibility": "See above. Novelty is incremental. ", "content.summary_of_the_review": "See above. ", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zaq4LV55xHl"}
{"id": "slGFo8_pOJ", "forum": "zAxuIJLb38", "replyto": "zAxuIJLb38", "invitation": "ICLR.cc/2023/Conference/Paper3782/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3782/Reviewer_4t9e", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3782/Reviewer_4t9e", "tcdate": 1666782269040, "tmdate": 1666783253149, "date": 1666782269040, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This work performs knowledge unlearning in large language models by attempting to fine-tune a converged model for a few epochs with a negative loss corresponding to the examples to the forgotten. As compared to past work which considers data duplication as a strategy towards reducing memorization, this work shows that knowledge unlearning can be very efficient, and does not reduce the LM performance significantly.\n\nThe authors also propose a metric to quantify if an example is forgotten, and call it the EL or Extraction Likelihood. Coupled with a metric for memorization, the work \n\nSome other interesting findings include that the domain of the data to be removed has a large impact on the ease of forgetting of the example. Further, removing small batches of data sequentially is better than removing large batches at once.", "content.strength_and_weaknesses": "## Interesting Results and Strengths\n1. The paper is very well written and follows easily, providing enough background to the reader wherever needed.\n2. The experimental setup is comprehensive with LM performance compared to a variety of tasks. And benchmarks the results for future work to improve upon.\n3. Many of the experimental decisions taken in this work were interesting: for example, using OPT method to replicate a deduplicated dataset, and using data from the Extraction dataset to measure unlearning.\n4. While the LMs scale to larger sizes, it takes fewer epochs for the target sequences to be forgotten. \n5. Sequential Unlearning is more Stable than Batch Unlearning. Do you have any intuition as to why this happens?\n\n## Weaknesses\n1. Thresholds: The thresholds should be set as mean + k* standard deviation and not just the mean. This current approach does not guarantee that with a high probability the examples are forgotten. How do the results change after making this modification?\n2. EL_n value: How was the value of n set to 10\n3. The Ablation/Understanding section of this paper is weak. In particular, the authors do ask all the right questions: \"Why Are Some Instances Harder to Forget?\" \"Why Are Some Instances Harder to Forget?\"  but the study only provides empirical evidence to rehash the same phenomenon without much understanding gained for the reader. The experimental study rather answers the question: \"Are Some Instances Harder to Forget?\" and so on.\n4. Comparisons with prior work: While there is no significant literature for unlearning in the LM domain, it would have been nice for the authors to utilize the compare the best unlearning algorithms in the vision domain, and see if they can leverage the advances in the vision domain in the NLP domain.\n5. The authors use the term \"guarantees privacy\" for model extraction attacks. I would not use terminology like guarantee for empirical evidence.", "content.clarity,_quality,_novelty_and_reproducibility": "While there may not be a lot of novelty in the methods designed in this work, I do believe that it has a significant contribution to the field of machine unlearning in large LMs. The quality of writing is good, and the authors provide code for reproducibility.", "content.summary_of_the_review": "I find that this paper does an important job of benchmarking initial results for unlearning in the context of large language models. The paper presents an optimistic picture for LMs suggesting that even with baseline unlearning methods, one can achieve forgetting without hurting LM perform. The experimental study is comprehensive and allows future work to build upon with the released code.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zAxuIJLb38"}
{"id": "n5SXHe6iq8", "forum": "zAxuIJLb38", "replyto": "zAxuIJLb38", "invitation": "ICLR.cc/2023/Conference/Paper3782/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3782/Reviewer_jyEc", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3782/Reviewer_jyEc", "tcdate": 1666679548925, "tmdate": 1668710167709, "date": 1666679548925, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper proposes a simple method for unlearning training samples, to comply with GDPR (and other privacy acts') right-to-be-forgotten statement, which gives each person the right to delete their data at any time they want. The proposed unlearning method for language models involves doing a gradient ascent (instead of the usual descent) step, minimizing the likelihood of the training samples. The authors empirically show that this negative step can decease the memorization of the sample, based on the metrics they introduce themselves. They also compare the unlearning method they introduce to a deduplication baseline.  They also demonstrate that unlearning samples sequentially provides a better utility, than unlearning samples all at once.", "content.strength_and_weaknesses": "Strengths:\n\n1. The method is simple and intuitive and has nearly no overhead. \n2. The problem is timely and relevant.\n\n\nWeaknesses:\n\n1. There are some experimental and design decisions that seem arbitrary and I don't really see the reasoning behind: \n    a. The choice of baseline: I don't really see why deduplication is chosen as a baseline to compare to? It seems the most irrelevant and also the most compute-intensive one. The proposed method is not at all similar to deduplication, which is a pre-processing method. Also, deduplication itself is really not a valid 'privacy protection method. I think the most appropriate baseline would actually be doing differential privacy, like DP-SGD, and then doing a comparison of memorization. So for instance if you wanna delete sample `a', you'd train a model on the full dataset, then unlearn it using your method, and then measure `a's memorization before and after. Then, you'd compare this with memorization of 'a' but under a model trained with DPSGD. DPSGD is the best point of comparison as by design, it is supposed to protect the membership, so it is like a pro-active approximate deletion method.\n\nb. The proposal of the privacy metrics: I wonder why the authors made up their own metrics, and also came up with an arbitrary privacy guarantee which is based on their two metrics. Why not just use membership inference attack recall [1,2] and exposure metric [3], which are commonly used and established metrics? These two basically do what the currently proposed metrics do. \n\nc. apart from not having an appropriate baseline, the paper also fails to even qualitatively compare, or even introduce in related work, to 'approximate deletion' methods and other descent-based methods such as [4,5] which are also aimed at deletion, w/o full re-training. \n\n\n2. Figure 1 is actually inaccurate in terms of DP, as you do not need to re-train with DP every time you get a deletion request, given how DP is actually defined. \n\n[1]   Shokri, Reza, et al. \"Membership inference attacks against machine learning models.\" 2017 IEEE symposium on security and privacy (SP). IEEE, 2017.\n\n[2] Mireshghallah, Fatemehsadat, et al. \"Quantifying privacy risks of masked language models using membership inference attacks.\" arXiv preprint arXiv:2203.03929 (2022).\n\n[3] Carlini, Nicholas, et al. \"The secret sharer: Evaluating and testing unintended memorization in neural networks.\" 28th USENIX Security Symposium (USENIX Security 19). 2019.\n\n[4] Izzo, Zachary, et al. \"Approximate Data Deletion from Machine Learning Models.\" arXiv preprint arXiv:2002.10077 (2020).\n\n[5] Neel, Seth, Aaron Roth, and Saeed Sharifi-Malvajerdi. \"Descent-to-delete: Gradient-based methods for machine unlearning.\" Algorithmic Learning Theory. PMLR, 2021.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and well-structured. The proposed method seems novel to me and the paper seems reproducible. However it is lacking justification for the choice of baselines and metrics.", "content.summary_of_the_review": "The paper's idea is interesting, simple, and effective. However, I think a better baseline and better metrics are needed to be able to actually say that it outperforms other methods. I think a comparison with DP is needed, and also a comparison with other approximate deletion methods is also needed.\n\n\n", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zAxuIJLb38"}
{"id": "Hv9sFYvjR4W", "forum": "zAxuIJLb38", "replyto": "zAxuIJLb38", "invitation": "ICLR.cc/2023/Conference/Paper3782/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3782/Reviewer_9RUh", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3782/Reviewer_9RUh", "tcdate": 1665861625299, "tmdate": 1670895181381, "date": 1665861625299, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "The authors propose a simple approach for unlearning specific token sequences in large pretrained language models (LMs). To unlearn a specific sequence of tokens x, the proposed approach simply negates the original training objective of minimizing the negative log-likelihood of x; this procedure is also known as unlikelihood training. To measure the effectiveness of unlearning, the authors introduce two metrics, extraction likelihood (EL), and memorization accuracy (MA). EL is measured as the average n-gram overlap between the output of the LM given the tokens in x up to token t and the ground-truth tokens greater than or equal to t. MA is the fraction of tokens output from the LM that match the tokens in x. The \"forgetting\" of x is achieved when the EL and MA of x is lower than the average EL and MA over token sequences in a validation set not seen during training.\n\nExperiments are performed using three different sizes of the GPT-NEO LM pretrained on all the PILE corpora. After unlearning, the LM is evaluated using 9 different domain datasets spanning a wide range of downstream NLP tasks. The results show the proposed unlearning approach achieves better unlearning (evaluated using the proposed metrics described above) than the most relevant competing method (a data pre-processing de-duplication approach) while maintaining better utility on most the of downstream NLP tasks; this is especially evident as the size of the GPT-NEO model increases. The authors also find their proposed approach is up to 3,500,000x more efficient than retraining from scratch.", "content.strength_and_weaknesses": "Strengths\n---\nUnlearning for large LMs is certainly a timely problem since large LMs have exploded in popularity, and are used as the foundation for almost all downstream NLP tasks, exacerbating any privacy concerns inherent in the pretrained LM. Thus, this work tackles an important problem of helping to mitigate some of the privacy issues that are likely to arise through the widespread use of large pretrained LMs.\n\nThe proposed approach is very simple yet effective and extremely efficient in comparison to retraining from scratch, which is generally intractable for large pretrained LMs. This makes the proposed approach very practical and likely to be used in the real world; it is also a much more appealing option than data preprocessing and expensive differential privacy methods.\n\nExperiments using various LM model sizes, and evaluations on 9 different domain datasets provide decent evidence the proposed approach is a potentially viable unlearning method that warrants further study.\n\nWeaknesses\n---\nThe forgetting guarantee requires extra validation data.\n\nNo results that vary the size of n, the hyperparameter used for the EL metric. This can give better insight into how much of the target examples are unlearned when the prompt varies in size. Additionally, how much does the success of the EL metric vary depending on which n tokens are used as a prompt for this metric?\n\nOnly a small number of examples (32) are randomly selected to be unlearned. Have the authors tried unlearning much larger portions of the training data and observing the effect on the resulting model?\n\nIt is still not quite clear to me why unlearning a larger batch of examples (128 vs 32) performs significantly worse than sequentially unlearning smaller batches of 32 examples at a time.\n\nQuestions/Comments\n---\nHow is the \"hardness\" of forgetting defined. Is it how much predictive performance changes when unlearning an example? Or, is it defined as the number of epochs to successfully achieve forgetting for the given input?\n\nThe improved forgetting and utility performance of the larger GPT-NEO model compared to the smaller versions is interesting. I would think these results suggest unlearning is \"easier\" for larger LMs with potentially more representational power.\n\nDo the authors have any insight into the relation between a model that uses the proposed unlearning mechanism and a model retrained from scratch without the target training examples to be removed?\n\nMinor Weaknesses\n---\nTable 3 is not color-blind friendly, consider showing prefixes as underlined text instead of blue-colored text.\n\nFootnote 6 (in the conclusion) should come after the period.", "content.clarity,_quality,_novelty_and_reproducibility": "The work appears novel, the writing is clear and is easy to read, and the approach is simple and straightforward enough that reproducing the results is likely feasible.", "content.summary_of_the_review": "Given the ubiquity of large pretrained LMs in NLP today, concerns related to privacy are likely to arise, thus new proposals for tackling these privacy implications is important. This work presents a simple, efficient, and effective approach for targeted unlearning in large LMs, and is likely worthy of further research.\n\nPost-Rebuttal\n---\nThis work applies gradient ascent to a new domain, namely large language models that are typically prohibitively expensive to retrain, enabling an efficient way to remove specific training sequences post-hoc. However, the empirical evaluation does not seem to fully support the main claims made in this paper. A more thorough investigation analyzing the predictive performance of the LLM as more instances are unlearned would greatly improve this paper and ultimately help readers and practitioners better understand the limitations of this approach. Also, better understanding the difference between sequential and batch unlearning would also significantly improve this paper.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zAxuIJLb38"}
{"id": "1G8CpoUVUxr", "forum": "zAxuIJLb38", "replyto": "zAxuIJLb38", "invitation": "ICLR.cc/2023/Conference/Paper3782/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3782/Reviewer_hH19", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3782/Reviewer_hH19", "tcdate": 1667248994092, "tmdate": 1667248994092, "date": 1667248994092, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "Memorization is a key emerging privacy risk in recent large-scale language models, wherein models can remember and regurgitate verbatim samples from the training set. This paper proposes to alleviate this problem via \"knowledge unlearning\", which is essentially running stochastic gradient *ascent* on samples that have been identified as memorized. The paper explores a few details on how this is done correctly (proposing sequential unlearning), and shows that the method can mitigate many verbatim generations.", "content.strength_and_weaknesses": "Strengths:\n* Memorization is a key problem to stop, and more empirical techniques are needed that do not sacrifice performance as differential privacy does. \n\nWeaknesses:\n* One of my big concerns is regarding the privacy evaluation of the method. The evaluation focuses specifically on preventing exact verbatim memorization. A trivial baseline for stopping verbatim memorization is to just manually block the model from generating exact strings in the training set, potentially using a suffix tree like is done in Kandpal et al. 2022 and Katherine Lee et al. 2022. Of course, this trivial baseline cannot prevent models from privacy risks such as (1) generating paraphrases of training texts, (2) leaking private information in a QA or dialogue setting (e.g., ask someone's SSN), and (3) cannot stop membership inference attacks. To show the benefits of the method, it'd be great to see results in some of the above (or related) evaluations. For example, run the membership inference methods from Kandpal et al. 2022, Carlini et al. 2020, or others.\n* Definitely checkout the privacy onion paper (Carlini et al. 2022) for another potential risk---unlearning some data can expose others.", "content.clarity,_quality,_novelty_and_reproducibility": "* I have some concerns regarding the technical novelty. The general idea of gradient ascent on some data to cause models to avoid learning is an idea that has been well-explored in the literature. For example, the canonical Ganin et al. 2015 paper that proposes \"gradient reversal\" layers. More recently, there is the large body of work on machine unlearning. Although the paper is correct that this is mainly focused on CV and basic regression tasks, there isn't a ton of new technical novelty required to apply the ideas to NLP.   \n* I find it weird to discuss de-duplication as a sort of baseline. Deduplication should be almost always used as a first data processing stage to mitigate memorization (Kandpal et al. 2022; Carlini et al. 2022), and in that sense, it's quite orthogonal to the method proposed here. \n* The quality and clarity is otherwise great, easy to read and follow. Reasonable experiments.\n", "content.summary_of_the_review": "I find the method to be quite similar to past ideas and the privacy evaluation to be a bit limited.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zAxuIJLb38"}
{"id": "zbo7ShwtKGO", "forum": "zClyiZ5V6sL", "replyto": "zClyiZ5V6sL", "invitation": "ICLR.cc/2023/Conference/Paper2874/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2874/Reviewer_hniQ", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2874/Reviewer_hniQ", "tcdate": 1666763929667, "tmdate": 1666763929667, "date": 1666763929667, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "The authors propose an algorithm named TiAda which is a time-scale adaptive algorithm for non-convex-strongly-convex (NC-SC) minimax problems. The algorithm is a single loop and problem-specific parameter agnostic one, which are improvements over the related prior work. The authors provide insight into the design of the algorithm, theoretically analyze the algorithm and empirically validate its usefulness of the algorithm.  The authors also provide some generalization of TiAda to other adaptive methods and empirically validate their usefulness against related baselines.\n", "content.strength_and_weaknesses": "**Strengths:**\n\n1. The proposed method improves upon the main related prior work such as similar implementation in deterministic and stochastic cases (agnostic to the noise level in the gradient). It does not need complex subroutines in the inner loop update for termination.\n2. The work provides extensive validation of the proposed method against related baselines, in their experimental setting, and provides an ablation over some proposed algorithm-specific parameters.\n3. The intuition of the work is clear and the paper is easy to follow.\n\n**Weaknesses:**\n\n1. The rate obtained in Theorem 3.2 is worse compared to state-of-the-art Na-Ada. Could you explain the reason behind this worse rate?\n2. It is unclear how the list of values for r is chosen for results in Figure 2. What is the reason for choosing different orders of ratios for the two other experiments? It seems like NeAda would perform better for smaller choices of r. Furthermore, how was $\\eta_x$ (or $\\eta_y$) chosen for these experiments?\n3. It is not clear why Na-Ada is not included in GAN simulation in Figure 4. \n4. Some typos in the text (e.g. definition in Assumption 3.2). \n", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is well-written and easy to follow. The intuition behind the algorithm is clear. While the algorithm has some features of prior work, the improvements made by the proposed method are somewhat novel.\n", "content.summary_of_the_review": "The paper proposes a parameter-agnostic adaptive algorithm for solving NC-SC minimax problem. The authors have identified a gap in the literature in this regard and have provided a somewhat novel contribution. The authors provide the intuition as to why their solution addresses the prevailing issues, and theoretically and empirically justify their claims. The algorithm seems to be robust to the hyperparameter choices required by the algorithm, as per the results shown by the authors. The empirical results provided by the authors suggest the proposed methods outperform related baselines. There are some issues regarding the experimental setup in some of the empirical results, as mentioned above under â€œWeaknessesâ€. Furthermore, the theoretical results do not improve the prior work in the stochastic setting.\n", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zClyiZ5V6sL"}
{"id": "qWmJLwSMCX", "forum": "zClyiZ5V6sL", "replyto": "zClyiZ5V6sL", "invitation": "ICLR.cc/2023/Conference/Paper2874/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2874/Reviewer_K2fD", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2874/Reviewer_K2fD", "tcdate": 1666554082196, "tmdate": 1671004813622, "date": 1666554082196, "content.confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.", "content.summary_of_the_paper": "This paper proposes a single-loop adaptive gradient-based algorithm for solving nonconvex-strongly-concave problem with provably efficiency. Previous works only consider directly applying adaptive update scheme to x and y separately thus break the time-scale separation rule which is vital for guaranteeing the convergence. In this paper, the author proposed to adopt a more conservative stepsize for x so that the time-scale separation rule can be followed. The method is simple but effective. The author provide both theoretical and empirical result to verify the effectiveness of their proposed algorithm.", "content.strength_and_weaknesses": "Strength:\n(1) It seems to be the first provably efficient adaptive gradient-type algorithm in the non-convex-strongly-concave optimization\n(2) The technique proof is solid and the method is very nature and intuitive\n(3) This paper provides sufficient empirical evidences\n\nWeakness:\nThe major weakness is the sample complexity result in the stochastic setting, which is slightly worse than the standard result (standard is $\\epsilon^{-4}$ and this paper gives $\\epsilon^{-4-\\delta}$). It seems that this additional $\\delta$ is caused by the single-loop structure and the stepsize scheme thus is hard to improve. I notice that in the experiments the value of $\\delta$ is not very small, which means that in theoretical the convergence rate is much worse than SOTA.", "content.clarity,_quality,_novelty_and_reproducibility": "(1) How would the algorithm performs if the value of $\\delta$ is very small, e.g., at the order of 1e-4 ?\n(2) I feel like the additional dependence on $\\delta$ is mainly caused by the single loop structure. If we design the algorithm in a nested-loop way, in which we apply adaptive gradient update for both x and y separately, then it seems that we have a good chance to obtain a total sample complexity of $\\epsilon^{-4}$, which is better than the rate established in this paper. Can the author discuss a little more about that? If that is the case then the contribution of this paper might not be strong enough.", "content.summary_of_the_review": "Overall this paper is well-written and easy to follow. The algorithm proposed in this paper is also very interesting and intuitive. The only weakness of this paper is its sample complexity result in the stochastic setting, which could either caused by the nature of the algorithm or the proof technique. I will give borderline accept score for now. If the author can address such an issue later I will consider further increase my score.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zClyiZ5V6sL"}
{"id": "ZIAI-TYoh0T", "forum": "zClyiZ5V6sL", "replyto": "zClyiZ5V6sL", "invitation": "ICLR.cc/2023/Conference/Paper2874/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2874/Reviewer_Grdi", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2874/Reviewer_Grdi", "tcdate": 1666653445719, "tmdate": 1666653445719, "date": 1666653445719, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "In this work, the authors propose a single-loop adaptive GDA algorithm called TiAda for nonconvex minimax optimization that automatically adapts to the time-scale separation. The algorithm is parameter-agnostic and can achieve near-optimal complexities simultaneously in deterministic and stochastic settings of nonconvex strongly-concave minimax problems. The effectiveness of the proposed method is further justified numerically for a number of machine learning applications.", "content.strength_and_weaknesses": "Strength: adaptive stepsizes to nonconvex minimax problems in a parameter-agnostic manner.  \n\n\nWeaknesses: experiment is too simple to verify the algorithm effectiveness. ", "content.clarity,_quality,_novelty_and_reproducibility": "clear to follow \n\ncode provided for verification ", "content.summary_of_the_review": "The authors propose a single-loop adaptive GDA algorithm for nonconvex minimax optimization that automatically adapts to the time-scale separation. Only some simple experiment are conducted to verify the algorithm effectiveness. ", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zClyiZ5V6sL"}
{"id": "UXhu1ldwrv4", "forum": "zClyiZ5V6sL", "replyto": "zClyiZ5V6sL", "invitation": "ICLR.cc/2023/Conference/Paper2874/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper2874/Reviewer_1pAx", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper2874/Reviewer_1pAx", "tcdate": 1666704631593, "tmdate": 1666704631593, "date": 1666704631593, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "Finding an approximate stationary point of a nonconvex(-strongly-concave) minimax problem usually requires the knowledge of problem-dependent parameters, especially the step-size ratio between $x$ and $y$. The most relevant method, named NeAda, is the first parameter-agnostic (adaptive) gradient method for nonconvex minimax problems, but this is double-loop, does not have the optimal complexity, and has several other drawbacks as mentioned in the paper. This paper thus proposes a single-loop parameter-agnostic (two-time-scale) adaptive gradient method, named TiAda, which resolves aforementioned drawbacks of NeAda. There already exist single-loop two-time-scale adaptive gradient methods, but they only work with the knowledge of the problem-dependent parameters. The main new ingredient of the TiAda is having the effective step-size ratio of $x$ and $y$ being upper bounded by a decreasing sequence, making the ratio eventually decrease below the step-size ratio threshold. TiAda (with theoretical result) and other adaptive variants are found to work well in practice.", "content.strength_and_weaknesses": "- S1: The method is parameter agnostic.\n- S2: This achieves the optimal complexity for the deterministic case, and the near-optimal complexity for the stochastic case, which improves upon those of NeAda.\n- S3: This can be easily generalized to accommodate other existing adaptive schemes.\n- W1: Although $\\alpha$ and $\\beta$ are chosen to be $0.6$ and $0.4$ as a default throughout the experiment, they are hyper-parameters that might ask for tuning in other practical problems.", "content.clarity,_quality,_novelty_and_reproducibility": "The contribution and the originality of this work are clearly written in the paper.", "content.summary_of_the_review": "This paper constructed a single-loop two-time-scale parameter-agnostic adaptive gradient method, named TiAda, for nonconvex  minimax problems, which resolves issues with the first existing parameter-agnostic method, named NeAda. This TiAda method is a simple modification of existing two-time-scale adaptive gradient methods for minimax problems, but it is quite effective both in theory and practice. I believe this work is an important step towards resolving the non-convergence in practical minimax problems.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zClyiZ5V6sL"}
{"id": "hQW4UMkhmK", "forum": "zDiHoIWa0q1", "replyto": "zDiHoIWa0q1", "invitation": "ICLR.cc/2023/Conference/Paper1906/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper1906/Reviewer_ENpU", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper1906/Reviewer_ENpU", "tcdate": 1666379418275, "tmdate": 1666379418275, "date": 1666379418275, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "The paper analyses the phenomenon of grokking (discovering solutions that generalise well after the model has overfit the data) from the perspective of loss landscapes, specifically the disparity between the training and the generalisation landscapes. The authors show that grokking can be induced on standard ML benchmarks such as MNIST classification by (1) increasing the weight initialisation range, (2) drastically reducing the number of data points in the training dataset. Further, the authors conduct experiments to show that grokking is linked to the correlation between the discovery of a good representation and generalisation. For loss landscapes analysis, low-dimensional projections are used, where the weights are represented as a weight norm. The reduced 1D loss landscape visualisation seems to be a powerful tool.", "content.strength_and_weaknesses": "Strengths:\n\n1) The loss landscape perspective is refreshing and very tangible, I think this is the right way to think about the problem of grokking.\n2) Reduced 1D loss landscapes are a powerful visualisation tool, and may find further uses in the NN analysis and understanding.\n3) Empirical results are convincing.\n\nWeaknesses:\n1) The authors refer to â€œstandard initialisationâ€, and then explain that it stands for default initialisation in PyTorch. While this can be easily looked up at the time of writing, I am not in favour of such loose definitions. What if the next version of PyTorch picks a different default? Surely that should not lead to non-reproducible results. As such, I would like to request the authors to rather define the initialisation scheme explicitly.\n2) Even though the authors have managed to induce â€œgrokkingâ€ for MNIST and other tasks, the exercise seemed very artificial: yes, we can induce grokking by chopping off most of the dataset and raising the initialisation range. However, grokking does not seem to be something that we necessarily want to induce: looking at the results obtained, avoiding overfitting in the first place seems to still be the better option. Is the significance of this phenomenon perhaps blown out of proportion? I wish the relevance of grokking to standard ML tasks in light of the new experiments was discussed a bit more thoroughly.\n3) The paper has minor language mistakes:\nPage 5: â€œFor large data size say the full datasetâ€ -> e.g. the full dataset\nPage 6: â€œby constrastâ€ -> contrast \nPage 9: â€œdramaticnessâ€ -> not a valid word, rather use â€œseverityâ€", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is mostly clear and well-written. To me, the reduced 1D loss is the strongest contribution of the paper, since it is a general tool for loss landscape analysis, and we do not have enough of those. The link to representation learning is interesting, although, just like with grokking in general, I am left with a â€œso what?â€ question. Nonetheless, this is most definitely an original, interesting work.", "content.summary_of_the_review": "Overall, this is a good paper with brilliant loss landscape visualisations. Please refer to the least of strengths and weaknesses for the justification of my recommendation.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zDiHoIWa0q1"}
{"id": "TYmNC77FoZ", "forum": "zDiHoIWa0q1", "replyto": "zDiHoIWa0q1", "invitation": "ICLR.cc/2023/Conference/Paper1906/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper1906/Reviewer_itfw", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper1906/Reviewer_itfw", "tcdate": 1666726446223, "tmdate": 1666726446223, "date": 1666726446223, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper proposes the LU mechanism for the phenomenon of Grokking observed by Power et. al. 2020 - which states that the train and test curves follow an L and U shaped curve with weight norms respectively. They verify this observation in a student teacher setup, and show that it can arise in non-algorithmic datasets if initialized in a certain weight regime for appropriate sample size. Further, they try to differentiate the algorihtmic and non-algorithmic datasets in terms of their dependence on representations. ", "content.strength_and_weaknesses": "Strengths:\n1. The LU mechanism hypothesis is clearly stated, and the proposal to construct the landscape with fixed weight norm solutions is a nice idea to verify it (barring the possible optimization concerns for the constrained optimization problem). \n2. The experiments on MNIST, IMDB support the LU mechanism hypothesis - I particularly liked Figure 3 as it illustrates the idea clearly.   \n3. The authors are able to demonstrate grokking for non-algorithmic datasets by changing the sample size and weight initialization - this is an important finding.  \n4. The proposed difference between algorithmic and non-algorithmic datasets is plausible - in particular that the weight norm increases and then drops as in Figure 9. The representation messiness argument also supports this conclusion, but I found this to be a little weak (see comments below). \n\nWeaknesses:  \n1. Representation messiness:   \n- The experimental setup is hard to understand in Section 5.1 - I would suggest the authors include an appendix section describing the exact architecture, and the trainable/frozen components of this architecture. Does R_random depend on the input at all? If not, how is this a good proxy for representation learning?  \n- This part of the paper makes a reduction to a different architecture (from Liu et. al. 2022) and assumes that the representations are a convex combination of linearly separable and random gaussian representations. It is not clear to me why this is general and if the conclusions transfer to a setting where the representations are learnable (as is the case in grokking generally). \n2. Minor complaints:  \n- The authors claim that changing the x-axis to weight norm removes double descent - this is only true for some limited cases and does not hold generally for neural networks as is also stated in the reference cited by authors. I would recommend that the authors add this clarification.  \n- Figure 6: Please state which experimental setup these loss landscapes have been plotted for. \n", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is written fairly clearly and the figures convey the main points. The experimental setup is unclear in Section 5.  \nQuality: The hypothesis is well-formed and the experiments support the hypothesis.  \nNovelty: To my knowledge, this paper is the first to show grokking for non-algorithmic datasets. While there have been some papers that explore some aspects of grokking, this paper adds to that literature.  \n", "content.summary_of_the_review": "The authors state three conclusions in their paper - the LU mechanism, the occurrence of grokking for wide range of datasets under certain conditions and the dependence of grokking on learning representations. The first two are well-supported by their experiments as the setup is general enough that the conclusions are believable. However, the third conclusion is made in an artificially reduced setup. While this setup supports the hypothesis, it is unclear to what extent this is related to the general phenomenon of grokking where representations are learnt and not fixed. Nevertheless, the contribution of the first two conclusions and weak evidence for the third conclusion seems enough for acceptance to the conference. I would recommend the authors include some discussion for their choice of setup in Section 5.\n\n", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zDiHoIWa0q1"}
{"id": "DVSEq4b-Sj", "forum": "zDiHoIWa0q1", "replyto": "zDiHoIWa0q1", "invitation": "ICLR.cc/2023/Conference/Paper1906/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper1906/Reviewer_wgE4", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper1906/Reviewer_wgE4", "tcdate": 1666128085436, "tmdate": 1668640392486, "date": 1666128085436, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper proposes an explanation for when grokking happens---that it occurs when the initialization norm is too large so the model takes longer to get to the correct norm magnitudeâ€”and illustrates their thesis with results on synthetic and natural data. Defining grokking as a delay in generalization until after training set interpolation, they propose that grokking is caused by a mismatch between training and test loss curves, ie, overfitting, and described this pattern as the â€œLU mechanismâ€. They elicit grokking phenomena on natural data (IMDB and MNIST), at least if we define grokking as a delayed generalization curve. ", "content.strength_and_weaknesses": "Strengths:\n- This paper is well written and presented, a pleasure to read.\n- The experiments make the claims clear.\n- They successfully induce delayed generalization in natural datasets, suggesting that their claims might apply in realistic settings. These results happen outside of the teacher students set in, so they are more convincing than the algorithmic experiments.\n- The observation that larger dataset sizes expands the goldilocks zone is a very tidy way of thinking about generalization.\n- I found myself fairly convinced by the experiments that initialization magnitude is at least one factor that can induce grokking.\n- Itâ€™s good that they discuss the impact of weight decay repeatedly, as it is clearly an important factor.\n\nWeaknesses:\n- I do not generally consider it necessary to have a theoretical component of every empirical study, and many empirical studies make strong and intriguing claims that layout groundwork for a principled understanding. However, I think that the particular claims made in this paper would benefit enormously from a theoretical analysis. My issue is that they make out the initialization norm to be of particular significance, when other hyperparameters might (in fact, empirically do) have an equivalent â€œgoldilocks zoneâ€. Additional experiments about other hyperparameters might help, but I think that the insights that we can glean from purely empirical study of this phenomenon are limited. \n- I feel that the connection between overfitting and grokking is fairly obvious, as their own definition of grokking makes clear. Given the way that they implicitly define grokking, I donâ€™t believe that they can describe the LU mechanism as a â€œcauseâ€ rather than as a rephrasing of the same definition.\n- These settings used to illicit grokking are somewhat artificial: the initial norm, the constrained search space, the weight decay requirement. There is no satisfactory explanation given for why weight decay is so crucial; this is where a theoretical analysis might have been helpful.\n- Teacher student setups can fundamentally change training dynamics, so Iâ€™m not confident that the results from those experiments generalize to other settings. If the claims made from these experiments do not apply outside of a teacher student setting, Iâ€™m not sure I buy them. Especially because the particular representations learned by the teacher could easily require its own particular magnitude that is not necessary for all representations.\n- It is not clear to me what differentiates the LU mechanism from the existing concept of overfitting. Although they described their setup as different from â€˜related phenomenaâ€™  (Schoenholz et al., 2016; Yang and Schoenholz, 2017; Nakkiran et al., 2021), itâ€™s not clear to me how these citations are not directly describing the LU mechanism.\n- The effect that this paper attributes to the importance of representation learning (section 5) might be more precisely described as the effect of the distribution shift at inference time. \n- â€œWe treat the converging point after training as the global minimum on the spherical surfaceâ€ â€” why? Is this actually a convex a surface somehow?\n- It appears to me that the interpolations are between the final learned model and a random gaussian. It seems to me these experiments and plots would be more informative if the random model was the initialization weights, so that we could see a planar view of the path from initialization and not just any random direction. I personally would find that more convincing it as an explanation of the training process, compared with a random direction.\n- On importance of representation learning: it seems to me that this might best be described more precisely as the significance of distribution shift between train and test time. Otherwise, I would expect you to formalize what it would mean to have representation learning be important.\n- The discussion section: â€œ(ii) Pre-training avoids learning representations from scratch, hence helps reduce possible grokking.â€ But why wouldnâ€™t we see grokking in the pretraining stage itself?\n- Is it definitely the case that grokking is not observed in language models if you use larger initializations? Otherwise, you should probably remove the discussion section on language models entirely or present evidence that grokking does not happen at any stage. I don't think there's anything backed up in this section, and it doesn't really relate to the rest of the results. \n\nMinor/references:\n- You refer to default initialization settings in pytorch, but I think you need to give details about what those defaults are, as they might change between versions.\n- Footnote 2: Iâ€™m not sure this footnote should be there. It is well known that increased capacity allows tighter interpolation of the training set, but justifying this statement by presenting an artificial scenario in which a larger model is equivalent to the smaller model is not a reflection of real practices, where we would not initialize zero-vectors when expanding an architecture.\n- There is an existing literature on distinctions between multi epoch vs ideal infinite data sampling in practice, which might be worth digging into and adding to your citations, eg Nakkiran (2019) https://arxiv.org/abs/1912.07242\n- â€œWe run experiments with two initializations Î± = 0.5 (small) and Î± = 2.0 (large)â€ â€” Above, it said that alpha was the constant weight norm throughout training, but here it says that it is only the initialization. I can see now that this is supposed to just be the weight constraint, but itâ€™s a little confusing in the wording.\n- A number of these results, especially in the section on LU, seem to boil down to demonstrating that overfitting does exist. Iâ€™m not sure that this is necessary to make such a focus.\n- Formula 4 should have a citation to existing work on sharpness or linear interpolation.\n- Iâ€™m a little confused about the meaning of vâ€² = vcosÎ¸, given that Î¸ was previously defined as a thresholding value for the regression model, and I donâ€™t see how that definition connects to the use the variable in section 5.1. \n- This paper uses natbib. When you make an inline citation, e.g., â€œFoo et al. (2009) claimâ€¦â€ you should use \\citet{} instead of \\cite{} or  \\citep{} . An example of this issue is the entire first paragraph of section 6.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is extremely clear and seems to mostly be very reproducible, though I would like to see the footnote about pytorch modified to include details of the default initialization. The paper is of very high quality in general. \n\nThe novelty is middling, with some new ideas and some old ideas presented as new ideas (LU mechanism).", "content.summary_of_the_review": "I found many of the analyses here intriguing, and ultimately I would very much like to see this paper published. I was particularly impressed by their ability to induce grokking in a realistic setting. However, they seem to be making the claim that grokking is in general caused by initializing with a large norm. The experiments do not fully support that this is the case in the main setting in which grokking has been observed, which is the algorithmic setting. I would welcome more experiments around a wider set of hyperparameters, to demonstrate that delayed generalization does not result from other settings. Without these experiments or an added theoretical analysis, I don't feel confident recommending acceptance, but I'm ready to change my mind in response to a small number of additional experiments: evidence that the effects observed are particular to the norm magnitude and illustrations of the messiness plots but with the initialization weights instead of random weights, so that we can see something closer to the actual trajectory of training. Furthermore, I think that the paper should be somewhat modified in its definitions and reasoning, as the LU mechanism appears to fall almost trivially from their definition of grokking, rather than being an attributed cause.\n\n**After discussion:**\n\nI'm raising my score from 6 to 8 to reflect expanded experiments that lend some additional credence to the link between behavior in the algorithmic and natural settings, and the removal and finetuning of some unsupported speculation and imprecise connections. ", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zDiHoIWa0q1"}
{"id": "6_6vdMDUFz", "forum": "zDiHoIWa0q1", "replyto": "zDiHoIWa0q1", "invitation": "ICLR.cc/2023/Conference/Paper1906/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper1906/Reviewer_ceW8", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper1906/Reviewer_ceW8", "tcdate": 1666794393029, "tmdate": 1666794393029, "date": 1666794393029, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper studies the properties of grokking from the loss landscapes. The phenomenon of \"LU\" mechanism of the training and test loss is adopted to understand grokking from its dependence on data size, weight decay, and representations. In particular, the experiment tailor-designed to reveal the connection between grokking and deep representation learning is interesting and impressive. ", "content.strength_and_weaknesses": "Strength:\n\n(1) It is interesting and novel to understand grokking from the lens of neural loss landscapes. More importantly, the connection between grokking and data size, weight decay, and representation learning are demonstrated with sufficient empirical analysis. \n\n(2) It conducts sufficient and intuitive experiments to reveal the dependence of grokking on representation learning, which is helpful for the community to understand grokking in the learning process with complex datasets. Meanwhile, it contributes a useful new tool for characterizing data-model interaction and representation learning. \n\nWeaknesses:\n\n(1) Some terms should be explained in the paper for self-consistency, such as algorithmic datasets.\n\n(2) The color bar of Fig.6 (b) is in [0.4, 2.0], which is different from other figures. And as claimed in the paper, the error = 1 - acc. This is inconsistent. ", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity: This paper is well-written and easy to follow. \n\nQuality: High, all claims in this paper are well supported by thorough analysis and empirical experiments.\n\nNovelty: It is novel to understand grokking from the loss landscapes. The experiment results are impressive and interesting. \n\nReproducibility: Hard. As claimed in the paper, grokking itself is hard to observe and depends on many factors. \n", "content.summary_of_the_review": "Overall, it is a decent paper.  it proposes to interpret the grokking phenomenon from the perspective of loss landscapes. And sufficient empirical analysis is provided to support the claims of the paper. \n", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zDiHoIWa0q1"}
{"id": "jrigT2DPxd1", "forum": "zDjtZZBZtqK", "replyto": "zDjtZZBZtqK", "invitation": "ICLR.cc/2023/Conference/Paper905/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper905/Reviewer_cA4Y", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper905/Reviewer_cA4Y", "tcdate": 1666499755728, "tmdate": 1666499755728, "date": 1666499755728, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper proposes a variant of masked autoencoders (MAE), which is specifically designed for certified robustness tasks. Specifically, they add Gaussian noise in the pretaining process and use the consistency regularization method for finetuning. With a much smaller computational complexity, they obtain better results than the previous best results obtained by diffusion models.", "content.strength_and_weaknesses": "Strengths:\n1. Writing is easy to follow.\n2. The method is simple yet effective.\n3. Experiments and ablations are solid to support their arguments.\n\nWeaknesses:\n1. The method is highly established on MAE and previously proposed CR loss. The noise in pertaining can also be viewed as Gaussian noise data augmentation. There are not so many novel points.", "content.clarity,_quality,_novelty_and_reproducibility": "This work presents their methods very clearly. The detailed training process and parameters are listed, so it should not be hard to reproduce. Evaluation of novelty has been given in 'Strength And Weaknesses'.", "content.summary_of_the_review": "This paper proposes a simple yet effective self-supervised pretraining framework based on MAE. Although the key techniques are not new, I still would like to accept this paper because they are the first to come up with these ideas and make them work for certified robustness on large-scale datasets.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zDjtZZBZtqK"}
{"id": "imOc7cY_Yme", "forum": "zDjtZZBZtqK", "replyto": "zDjtZZBZtqK", "invitation": "ICLR.cc/2023/Conference/Paper905/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper905/Reviewer_E8Qx", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper905/Reviewer_E8Qx", "tcdate": 1666565559043, "tmdate": 1666644365449, "date": 1666565559043, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper proposed Denoising Masked Autoencoders (DMAE). DMAE added denoising training objective to MAE, and shows superior performance against previous works on $\\ell_2$ certified robustness tasks.", "content.strength_and_weaknesses": "Strength: The proposed method is simple and effective. \n1) It seems to be a natural fit for randomized smoothing, and I agree with the authors that there should be a more compact architecture than \"denoise + predict\". \n2) The results on $\\ell_2$ certified robustness surpasses previous works on ImageNet.\n\nWeaknesses:\n1) Explanation of why the proposed method achieves such good performance is desired.\nI am not sure if there is a more principled explanation on why a more compact architecture is sufficient to learn robust classifiers than than \"denoise + predict\". The explanation could be from a theory or experimental perspective. For instance, in Figure 2, the visualization of the reconstructed images seems to have some artifacts (the grid pattern). If one feeds the reconstructed image to a pretrained BEiT, I suspect the classification performance is not going to be good. However, it seems that directly using the encodings that learned from the encoder (the proposed method) gives good performance. Are there more principled explanations for that?\n2) More ablation studies are needed.\n-  In table 2, the proposed method needs to be retrained for different noise level. However, Carlini 2022 uses one model across all different evaluation settings. It'd be good to see the certified acc of DMAE for one model trained with one noise level but evaluated on different perturbation radii. \n-  Inference time is a key consideration in randomized smoothing (RS) since the large number of samples needed in RS. It'd be good to provide some quantitative evaluations for the inference time comparing with methods that use pretrained diffusion models. Comparing with standard diffusion denoising process, Carlini 2022 uses one-shot denoising instead of iterative denoising, which improves the inference speed. This paper directly uses a ViT based architecture, I am wondering if the inference time will be faster. ", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is mostly well written and the proposed method is clear and novel.\nThere is one point that could confuse people. The authors mentioned in both Intro and Method that Intro: \"such a two-stage process requires much more parameters and separated training\" and \"Carlini et al. (2022) took steps to train Gaussian smoothed classifiers with the help of unlabeled data\". This is not precise because Carlini 2022 only uses pretrained model and does not need any training for certified robustness. I understand that what the authors really want to say is that the off-the-shelf models used by Carlini 2022 need to be trained for two objectives, but the authors should make it clearer.\n", "content.summary_of_the_review": "This paper proposed a simple and effective method to train certifiably robust classifiers. Despite the simplicity of the proposed method, it outperforms previous works. More principled explanations of why the method works and more ablation studies are desired. ", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zDjtZZBZtqK"}
{"id": "cO8X2lLtMo0", "forum": "zDjtZZBZtqK", "replyto": "zDjtZZBZtqK", "invitation": "ICLR.cc/2023/Conference/Paper905/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper905/Reviewer_xxcH", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper905/Reviewer_xxcH", "tcdate": 1666668282056, "tmdate": 1668734654922, "date": 1666668282056, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper proposed Denoising Masked AutoEncoders (DMAE), a vision-transformer based neural network model, and showed that the certified robustness using randomized smoothing can be either comparable or better than state-of-the-art denoised randomized smoothing methods, such as Carlini et al., 2022.", "content.strength_and_weaknesses": "Strength: Paper is easy to follow. \n\nWeakness: The framework does not seem to be easily extendible to any pre-trained classifier, while in general denoised randomized smoothing methods can apply to any arbitrary classifier. Therefore, the scope is limited and the comparison is not entirely fair.", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity: clear presentation\nQuality: Applicability and comparison to denoised randomized smoothing need more justification\nNovelty: mediocre\nReproducibility: code not provided; unable to verify", "content.summary_of_the_review": "There are two major issues that I perceived and prevented me from giving a better recommendation.\n\n1. Limited applicability: The DMAE appears to be only applicable to vision transformer-based encoder-decoder and not directly extendible to other neural network models. On the other hand, denoised randomized smoothing applies to any pre-trained classifier and can certify different architectures. My one-sentence summary of this work's major contribution would be \"If one applies randomized smoothing on DMAE, it will get better or comparable certified accuracy than other (general-purpose) denoised smoothed models\". However, this argument ignores the fact that denoised smoothing applies to any arbitrary classifier while the proposed model does not. \n\n2. Unfair evaluation: Continue on my point #1, given that there is no fixed classifier in the proposed DMAE setting, I don't think comparing certified accuracy or model size makes any sense because it boils down to simply comparing the certified robustness a model (DAME) to different models (e.g., a fine-tuned vision transformer classifier). The results are not compared in a common setting and I don't see any new insights other than DAME shows good certified performance. If the goal is to show DAME is easier to certify, then more discussion on why this architecture is preferable to certification is required. But this aspect is lacking in the current manuscript. Overall, I would suggest the authors put some deep thoughts into making the comparison meaningful (e.g., trying to certify the same \"classifier\" while allowing the denoiser to vary), or making a deeper analysis of the source of better-certified robustness from the proposed model (again, proper baseline models/architectures would be needed here).", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zDjtZZBZtqK"}
{"id": "WFlCaX9zPz6", "forum": "zDjtZZBZtqK", "replyto": "zDjtZZBZtqK", "invitation": "ICLR.cc/2023/Conference/Paper905/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper905/Reviewer_Gj4g", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper905/Reviewer_Gj4g", "tcdate": 1666908865792, "tmdate": 1668623872362, "date": 1666908865792, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "In this paper, the authors study the provably/certifiable robust classification problem. Specifically, the authors propose a self-supervised framework called Denoising Masked Auto-encoders to learn robust representations (or to pre-train encoders) by reconstructing images from noisy and masked inputs. The authors further fine-tune the model with the consistency regularization technique to achieve optimal robust classification for the model.", "content.strength_and_weaknesses": "### Strengths\n\n(+) Results on existing tasks are good, showing the effectiveness of the proposed method\n\n(+) The work is well-motivated and the paper is easy to follow.\n\n(+) In addition to the certified accuracy evaluation, the authors include empirical studies to justify that DMAE learns more robust features than MAE.\n\n### Weaknesses\n\n(-) (major) The significance of the work may be limited and it is not well-positioned against existing works (i.e., MAE and Randomized Smoothing). The authors formulate their problem as to study the â€œrobust vision learnerâ€ and propose the representation learning (with pre-training & fine-tuning) paradigm to learn robust encoder. The pre-trained encoder should be general-purposed and be evaluated in multiple different downstream tasks, e.g., the robust segmentation on noisy inputs, following the MAE work. However, the current evaluation is only performed on the image classification problem with only 2 datasets. This could limit the significance of the method as a â€œvision learnerâ€œ.\n\n(-) (major) The proposed framework that adds noise to the training image and performs the masked reconstruction is straightforward given the desire of learning noise/attack robust encoders. Technically, it seems to be incremental to the MAE work and adapts MAE to the certified robust problem setting. Other techniques used in the paper such as consistency regularization are also from existing work. This may limit the novelty of this work.\n\n(-) (major) The proposed method is not sufficiently justified. Even focusing on the robust classification problem, the experiments may still not be sufficient to show the generalizability of the proposed approach. Current experiments only consider the Gaussian additive noise in both training and evaluation. The certified radius evaluation can cover those cases by selecting a large enough radius, but cannot fully justify or compare the model behavior under certain noise/attack types. In real scenarios, the noise/attack might be more diverse and complicated, e.g., Poisson, impulse, combined, or even dedicated to attacking certain models. It would be better to include more evaluation on some of those cases.\n\n(-) (minor) Does the robust fine-tuning (with regularizations) also be applied to baseline methods so that the comparison is fair? If not, it would be better to make comparisons consistently with/without the robust fine-tuning in order to show that the improvement comes from the DMAE pre-training framework.\n\n(-) (minor) To be more self-contained, it is better to include a better formulation of the certified robust classification problem and the evaluation protocol with the certified radius.\n\n(-) (minor) I also suggest the author discuss the self-supervised (blind-spot) image denoising paper [1, 2] since they are relevant and the frameworks are actually similar. The only difference is that the denoising approaches take the final images as outcomes and this work takes the representation or pre-trained encoder as outcomes. In particular, when considering the masked&noise reconstruction framework and the robust fine-tuning term (KL divergence between two outputs), the framework is very close in its looking to the objective in [2]. It would be better to discuss any connections and highlight differences between those works.\n\n[1] Batson et al. Noise2Self: Blind Denoising by Self-Supervision. ICML 2019.\n\n[2] Xie et al. Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising. NeurIPS 2020.\n", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity and Reproducibility: The authors study an interesting and well-motivated problem. The paper is well-written and easy to follow. Sufficient implementation details are provided for reproduction.\n\nQuality: The experiments done in the work indicate the effectiveness of DMAE to some degree. However, additional evaluations on more tasks and datasets may make the method more convincing.\n\nNovelty: The key idea is very straightforward given the problem setting and the proposed approach seems to be an adaptation of MAE in a stricter setting. Hence the novelty is limited.", "content.summary_of_the_review": "The paper studies an interesting problem and is overall easy to follow. Experiments done in the work can indicate the effectiveness of DMAE to some degree. However, there are some concerns about the novelty, significance, and insufficient evaluation of the work. I believe the paper would be a good one if the authors can show its capability in more tasks with noisy input (that would be a lot of empirical contribution), but the current form of this paper may not be good enough.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zDjtZZBZtqK"}
{"id": "v66IDkczqQ", "forum": "zEn1BhaNYsC", "replyto": "zEn1BhaNYsC", "invitation": "ICLR.cc/2023/Conference/Paper156/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper156/Reviewer_B1fn", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper156/Reviewer_B1fn", "tcdate": 1666660463138, "tmdate": 1668793427464, "date": 1666660463138, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "The authors study the problem of learning a linear operator from one RKHS to another RKHS (hereafter from an input RKHS to an output RKHS). In this literature, it is common to study a certain kind of mis-specification: what if the ground truth belongs to an interpolation space between the RKHS and L2. Whereas previous works on the problem consider the mis-specification with respect to the input RKHS, this work considers mis-specification with respect to both the input RKHS and the output RKHS, which is a generalization. The authors characterize the learning lower bound in generalized Hilbert-Schmidt norm and analyze a new multilevel estimator that attains it.", "content.strength_and_weaknesses": "See below", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity\n\nOverall, the paper was written in a very clear manner for kernel experts. It would be nice to at least point to other works that interpret the various abstract assumptions of Fischer and Steinwartâ€™s paradigm in a way that more readers can understand.\n\nThe remarks do a great job explaining the similarities and differences with prior work. Two additional references which I would like to be included in the â€œlearning with kernelâ€ paragraph of the related work are\n1. â€œA measure-theoretic approach to kernel conditional mean embeddingsâ€ (NeurIPS 2020), which was a relatively early work about learning rates, though not in Sobolev norm\n2. â€œKernel methods for causal functionsâ€ (arXiv 2022), which obtains optimal rates in Sobolev norm but only considers beta=1 and gamma=1\nNeither of these references diminish of the contributions of this work in any way, but would make the related work section more complete.\n\nQuality\n\nI only skimmed the proofs due to time constraints. The main results and main steps in the proof seemed reasonable.\n\nNovelty\n\nBy studying the harder learning scenario in which both the input and output RKHSs are mis-specified, the authors break new ground. The second rate in the bound, based on the output RKHS, seems to be interesting and novel.\n\nReproducibility\n\nGiven the proposal of a new multilevel estimator, I was a bit surprised that there were no simulations. The works in this literature that study well known estimators sometimes skip the simulations, but this paper seems to propose a new estimator and to claim that in certain â€œhardâ€ scenarios it is preferable. It raises the question of how difficult the new multilevel estimator is to implement.", "content.summary_of_the_review": "This paper joins a mature literature, but I think that its study of the output RKHS mis-specification is significant. The lack of simulations raises the question of how feasible the multilevel estimator actually is. If the authors implement the minor improvements suggested above, I will raise the score.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "10: strong accept, should be highlighted at the conference", "paper_forum": "zEn1BhaNYsC"}
{"id": "rHOGdJ912f", "forum": "zEn1BhaNYsC", "replyto": "zEn1BhaNYsC", "invitation": "ICLR.cc/2023/Conference/Paper156/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper156/Reviewer_Zt4i", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper156/Reviewer_Zt4i", "tcdate": 1666631557316, "tmdate": 1666631557316, "date": 1666631557316, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper considers the problem of learning a linear operator between two infinite-dimensional Sobolev reproducing kernel Hilbert spaces, which includes learning differential operators and condition mean embedding as special examples. A novel information-theoretical lower bound is derived, which implies that the minimax learning rate depends on both the smoothness of input and output spaces. This paper proposes a multi-level kernel operator learning algorithm that can achieve the optimal learning rate.", "content.strength_and_weaknesses": "$\\textbf{Strength}$\n\n1. This is a novel contribution that provides insights into the understanding of operator learning between two infinite-dimensional spaces, a topic with various applications in scientific computing, machine learning, and statistics.\n\n2. The minimax lower bound for learning a linear operator is interesting and novel, which characterized the difficulty of this problem.\n\n3. The proposed multi-level kernel operator learning algorithm also makes a solid contribution and the insights are valuable for the design of other operator learning algorithms.\n\n4. The mathematical analysis of this paper is rigorous and sound, which extends the previous results for learning differential operators and conditional mean embedding.\n\n$\\textbf{Concerns}$\n\n1. Can the analysis (or lower bound) be extended to nonlinear operator learning?\n\n2. The definitions of $\\hat{C}_{LK}$ in (3) and (5) are not given. It is also a little confusing how $\\hat{A}$ can be calculated in practice as $\\rho_j$ and $f_j$ are not easy to obtain.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is well-written with a sufficient literature review. The results are novel, significant, and of broad interest.", "content.summary_of_the_review": "The paper studies the optimal convergence rate of learning a linear operator between two infinite-dimensional spaces, which should be of interest to a broader audience in the field of machine learning and scientific computing.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zEn1BhaNYsC"}
{"id": "TRnEZVAJHQ", "forum": "zEn1BhaNYsC", "replyto": "zEn1BhaNYsC", "invitation": "ICLR.cc/2023/Conference/Paper156/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper156/Reviewer_7Ap7", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper156/Reviewer_7Ap7", "tcdate": 1666604291485, "tmdate": 1668595399821, "date": 1666604291485, "content.confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper considers the problem of deriving theoretical learning rate for learning mappings between infinite-dimensional function spaces. As noted by the authors, it is an important topic to understand how much training data is needed to approximate linear operators within a prescribed accuracy. After reviewing existing theoretical works on operator learning connected to PDEs, the authors derive a lower bound for learning linear operators between infinite-dimensional Sobolev reproducing kernel Hilbert spaces.", "content.strength_and_weaknesses": "### Strengths\n\n1. The problem of deriving theoretical learning rates for Hilbert-Schmidt operators addressed by this paper is a significant topic with applications to understand performance of state-of-the-art neural operators approach for learning solutions operators of PDEs.\n2. The authors derive a novel lower bound for learning linear operators between Sobolev reproducing kernel Hilbert spaces, generalizing existing works by Li et al (2022) which takes into account the output space (as opposed to prior works).\n3. The lower bound on the learning rate is optimal as shown by the authors who introduces a scheme achieving a near-optimal learning rate.\n\n### Weaknesses\n\n1. The paper is very technical and dense which makes its understanding very difficult beyond section 1. More backbround material should be provided in section 2 on reproducing kernel Hilbert spaces and Hilbert-Schmidt operators along with concrete examples connection to operator learning associated with PDEs.\n2. The lower bound provided by the authors in Theorem 3.1 is the main result for the paper but little explanation and interpretation is provided in the section and no comment on the proof techniques.\n3. The multilevel kernel operator learning scheme of section 5 seems interesting (based on the theoretical results in Theorem 5.1) but I don't understand the method, which is essentially described in one sentence by Eq. (5). I would suggest rewriting the section to describe the method extensively, eventually adding a simple illustrative examples.\n\n### Minor comments\n\n1. End of page 3: \"kernl\" -> \"kernels\"\n2. Could the authors add some interpretation on the assumptions for the kernel in section 2.2?\n3. Some equations are missing punctuations, e.g. Lemma A.1, A.3...", "content.clarity,_quality,_novelty_and_reproducibility": "The results obtained by the authors seem novel and high quality but the density of the paper prevents is clarity and is the main weakness.", "content.summary_of_the_review": "While the paper contains novel and significant results on the sample complexity of Hilbert-Schmidt operators, its technicality and density prevent the readability. I believe that a revised version of the paper, including the proofs in the main text and expanding on the background material and interpretation of the results, would be more suitable for a top machine learning journal like Journal of Machine Learning Research (with a longer review time allowing for a careful check of correctness) rather than a short conference paper with a long supplementary material.\n\n--\nI have updated my score following the authors' response.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zEn1BhaNYsC"}
{"id": "N0VRzPO6Ofv", "forum": "zEn1BhaNYsC", "replyto": "zEn1BhaNYsC", "invitation": "ICLR.cc/2023/Conference/Paper156/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper156/Reviewer_v7T2", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper156/Reviewer_v7T2", "tcdate": 1666332750575, "tmdate": 1666332750575, "date": 1666332750575, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper studies the problem of learning trace-class operators between Sobolev reproducing kernel Hilbert spaces. Information theoretical lower bound of convergence rates are derived. The machine learning problem is characterized by bias contour and variance contour on spectral spaces. Three regularization schemes are proposed inspired by the bias and variance contours. All three schemes are proven to achieve the minimax lower bound subject to a logarithmic factor.", "content.strength_and_weaknesses": "Strength\n1. Clear insights provided by bias and variance contours\n2. Important mathematical problem well motivated by many applications, including generative modeling, functional linear models, causal inference, multi-agent reinforcement learning, and so on.\n3. Analysis achieves minimax optimal rates\n\nWeaknesses:\nNo significant weakness has been identified.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is written with a very clear structure, and the idea of bias and variance contours are clearly illustrated with figures. The results are novel and of high scientific quality.\nSince this paper is on theoretical research, the reproducibility of theory is guaranteed by the provision of proof, and numerical reproducibility is not applicable.", "content.summary_of_the_review": "Inspiring characterization of bias and variance contours. Neat convergence analysis with the estimations achieving minimax optimal rate.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.details_of_ethics_concerns": "The paper studies machine learning theory, and there is no ethics concern.", "content.recommendation": "10: strong accept, should be highlighted at the conference", "paper_forum": "zEn1BhaNYsC"}
{"id": "0XFORg-Orb", "forum": "zEn1BhaNYsC", "replyto": "zEn1BhaNYsC", "invitation": "ICLR.cc/2023/Conference/Paper156/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper156/Reviewer_EtQp", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper156/Reviewer_EtQp", "tcdate": 1666612466127, "tmdate": 1666612466127, "date": 1666612466127, "content.confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "The paper analyses the problem of constructing maps netween infinite dim function spaces.  The paper claims 3 contributions:\n\n1. An information-theoretic lower bound of learning a linear operator between two infinite-dimensional Sobolev RKHSs consisting of two polynomial rates, the first of which depends on the input space and is consistent with known results, the second of which depends on the output space and is novel.\n\n2. A study of the shape of regularization needed to obtain the optimal learning rate.\n\n3. A setting where a multilevel training procedure is needed to achieve the optimal learning rate, which is distinct from the finite-dimensional case where a single-level estimator suffices.", "content.strength_and_weaknesses": "The paper is soundly written and to the best of my knowledge the theoretical contributions are novel and provide insight into the problem.  Examples are given to motivate the mathematical development and there is commentary describing salient points.\n\nMy one complaint is the lack of any summary of proofs in the body of the paper.  While obviously it is not practical to include the actual proofs, it is useful to include some indication of the important steps or interesting methods required in the body of the paper.", "content.clarity,_quality,_novelty_and_reproducibility": "As far as I can tell the paper is clear, and the results would appear to be novel.  I did struggle with some of the mathematics in the paper but I assume this has more to do with unfamiliarity on my part than any problems with the presentation itself.", "content.summary_of_the_review": "The paper presents novel results in what appears to be a thorough and informative manner.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zEn1BhaNYsC"}
{"id": "POSOW6sPRC", "forum": "zfiYcbeQkH", "replyto": "zfiYcbeQkH", "invitation": "ICLR.cc/2023/Conference/Paper6140/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6140/Reviewer_d6LN", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6140/Reviewer_d6LN", "tcdate": 1666536187881, "tmdate": 1666536187881, "date": 1666536187881, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "The authors of this paper introduce a benchmark for scientific representation learning consisting of 25 tasks in 4 formats (classificaiton, regression, ranking, search) and evaluate multiple general-purpose scientific representation learning methods (SciBERt, SPECTER, SciNL) alongside adaptation methods to learn task-specific and format-specific representations. The results suggest that fine-grained scientific document representations significantly out-perform general-purpose representations.", "content.strength_and_weaknesses": "Strengths:\n- Introduces a more comprehensive benchmark for scientific document representation learning\n- Clearly distinguishes SciRepEval from previous benchmarks (SciDocs) and justifies why a new benchmark is needed (low-power of the recommendation task, a need for more realistic task settings, and lack of training corpus)\n- Comprehensive ablation setup targeting fine-grained representation learning, multi-task learning with a strong base model\n\nWeaknesses:\n- It would have been nice to see an explicit section detailing what additional challenges remain in benchmarking scientific representation learning and how these limitations apply to the results seen with multi-task approaches.\n- Would have liked to see more discussion about task relatedness when discussing benchmarks, especially since SciRepEval seems to be designed in order to improve breadth and coverage of common real-world applications of the representations. For example, it would be interesting to see the relationship as applied to the task of choosing which sub-tasks to group for multi-task learning (see Efficiently Identifying Task Groupings for Multi-Task Learning; Fifty et al. NeurIPS 2021).", "content.clarity,_quality,_novelty_and_reproducibility": "Clarity: The paper is written clearly and the logic flows well.\n\nQuality: I believe this is a high quality paper with interesting results and strong justification.\n\nNovelty: The authors identify a challenge with existing benchmarks and release a larger and more diverse benchmark. This is an important and novel contribution.\n\nReproducibility: Data is promised to be released; no mention of code release.", "content.summary_of_the_review": "The authors identify an area of opportunity relating to current datasets and methods to evaluate scientific representation learning models and propose a well-grounded, larger benchmark in SciRepEval. The ablation study is comprehensive and there is some interesting discussion of cross-task analysis, although I would have liked to see that section expanded.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zfiYcbeQkH"}
{"id": "NZac4_IDVY", "forum": "zfiYcbeQkH", "replyto": "zfiYcbeQkH", "invitation": "ICLR.cc/2023/Conference/Paper6140/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6140/Reviewer_tJad", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6140/Reviewer_tJad", "tcdate": 1666473746927, "tmdate": 1666473746927, "date": 1666473746927, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper introduces SciRepEval, which is a novel benchmark for training and evaluating scientific document representations. Additionally, the struggles of multi-task learning with regards to generalization in these tasks is explored. An alternative that explicitly encodes the task type is offered and evaluated.\n", "content.strength_and_weaknesses": "Strengths\n\n- Not only are we treated to a single task in this benchmark, but 25, including classification, regression, and recommendation, each of which have appropriate measures for evaluation (though other measures may also have been appropriate).\n- Given the variety of tasks, a â€˜multi-formatâ€™ method of representation learning is proposed which is not entirely novel on its own, but is additively useful within this paper more ostensibly about the benchmarking suite.\n- Suitable baselines (SciBERT, SPECTER) and several extensions (e.g., CTRL-code and embedding adapters) provide a suitable evaluation suite.\n\n\nWeaknesses\n\n- Although much of the information is found in the Appendices, more detail on the tasks themselves are expected within the main body, especially with regards to the source of the data, which could likely be added to Table 1, in some form.\n- Tables 2 and 3 and their discussion in the text require some additional context to evaluate these results, especially with regards to the units of measure and highlighting that the first two columns are not exactly comparable with the third (SciDocs). Given the relative similarities of the performance between SPECTER and SCiNCL (especially considering the variants of each), statistical significance tests should be performed.  \n\n\nMinor\n\n- The use of task-specific control codes is reminiscent (somewhat) of ELMo, and a comparison or acknowledgement should be made to some of the literature around that model.\n- Some further explanation around the deficiencies of SciDocs in Sec 2 (especially with regards to the correlations and easiness of negative candidates) really should be provided, especially as SciRepEvalâ€™s superiority is meant to be evaluated in contrast to the former.\n- There is a higher-than-usual amount of repetitiveness, especially around the 25 tasks in SciRepVal in the first few pages, but this is a very minor complaint\n- Some deeper dive into how performance is affected by covariates such as the field of study (Table 8) after one filters out the effect of data set size would be interesting.\n- Be sure to check the formatting of your references\n", "content.clarity,_quality,_novelty_and_reproducibility": "- The paper is well-written. It does not go into very much technical depth, though it doesnâ€™t need to as a benchmarking paper, although the nature of the data could have been explored more fully. It is an extension of a previous benchmark in this space; while it is a substantial extension, this still limits its novelty. \n", "content.summary_of_the_review": "This paper extends an existing benchmark substantially, and offers a new approach to multi-task learning meant to deal with the multitude of tasks in a way that is not wholly novel, and beats the baseline, although only slightly. \n", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zfiYcbeQkH"}
{"id": "AKYRUOCmpRh", "forum": "zfiYcbeQkH", "replyto": "zfiYcbeQkH", "invitation": "ICLR.cc/2023/Conference/Paper6140/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6140/Reviewer_uueE", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6140/Reviewer_uueE", "tcdate": 1672985070771, "tmdate": 1672985070771, "date": 1672985070771, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "This paper introduces a new benchmark (SciRepEval) for scientific representation learning consisting of 25 tasks in 4 formats (classification, regression, ranking, and search). It shows that learning a separate document representation for each task format would improve the task performance compared to learning a single representation for all tasks.", "content.strength_and_weaknesses": "Strength\n- The authors provide a comprehensive analysis on 25 tasks in 4 formats. \n- The authors use strong baseline models to make the results more convincing.\n\nWeakness\n- There is not enough information on the tasks in the main content. Would be better to provide some high-level info there and left the majority in the Appendix.", "content.clarity,_quality,_novelty_and_reproducibility": "The paper is well written with high clarity and above-average quality.\nSome concerns on the Novelty, since the paper doesn't go deep on the technique.", "content.summary_of_the_review": "This paper is written in above-average quality and provides a new benchmark with a comprehensive analysis", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "6: marginally above the acceptance threshold", "paper_forum": "zfiYcbeQkH"}
{"id": "196nCVxVANN", "forum": "zfiYcbeQkH", "replyto": "zfiYcbeQkH", "invitation": "ICLR.cc/2023/Conference/Paper6140/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper6140/Reviewer_RNDk", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper6140/Reviewer_RNDk", "tcdate": 1667264560068, "tmdate": 1667264560068, "date": 1667264560068, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper introduces a new benchmark for scientific document representations, including 25 tasks across classification, regression, ranking and search. The paper also includes investigations on performances of existing models on the introduced tasks. ", "content.strength_and_weaknesses": "Strengths:Â \n- The paper consolidates useful tasks to make one benchmark for scientific document representations\n\nWeaknesses:Â \n- The models mentioned in the paper are mostly created by others in the community\n- The benchmark, while useful, is a consolidation of tasks that were already existing \n", "content.clarity,_quality,_novelty_and_reproducibility": "I did not find the paper to be novel, but the quality and clarity of the writing was sufficient", "content.summary_of_the_review": "While the paper provides a useful benchmark, there is a strong component of novelty missing from the paper. ICLR does not seem like the correct venue for this paper to be presented. ", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "1: The contributions are neither significant nor novel.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "3: reject, not good enough", "paper_forum": "zfiYcbeQkH"}
{"id": "846anjxQl3E", "forum": "zfodIZGVWW", "replyto": "zfodIZGVWW", "invitation": "ICLR.cc/2023/Conference/Paper3198/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3198/Reviewer_Ebn1", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3198/Reviewer_Ebn1", "tcdate": 1667343108438, "tmdate": 1667343108438, "date": 1667343108438, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "The paper introduces Amos, a first-order DL optimizer with adaptive learning rate and decay. The proposed contributions are:\n\n* Outperforming AdamW for pre-training language models\n* Providing guidance for hyperparameter tuning\n* Reducing memory usage\n* Allowing continuous training and resuming from checkpoints\n\nThe proposed optimizer leverages model-specific information, by partitioning the model parameters and adding a per-partition norm constraint. This norm constraint, together with the gradients, is used to adapt the learning rate and weight decay.\nThe parameter update involves a series of newly introduced hyperparameters with different functions, and the paper provides a series of heuristic derivations and experiments to set their values.\n\nIn experiments pre-training current architectures for NLP tasks, Amos is shown to outperform AdamW with 2019 settings in terms of speed, performance and memory usage.", "content.strength_and_weaknesses": "The idea of using model information to replace the hyperparameters is great, we have good examples of similar strategies from the weight initialization literature (Xavier, He) and extending this to adaptive optimizers sounds exciting. Furthermore, this combines also very nicely with the interplay between learning rate and decoupled weight decay, which has been recently proven useful to solve issues with first-order adaptive DL optimizers like Adam. Finally, it also brings better performance using less parameters in a block-wise regularized fashion.\nCombining these ideas is a very promising and well-grounded line of work.\n\nStill, the question of why specifically this model, is not fully clear to me, for the following reasons:\n* Compared to its counterparts, the model introduces increased complexity, but the motivation (section 1) lists reducing complexity as a goal. This is expected to be achieved through the \"guidance for hyperparameter tuning\", but I'm not convinced of such guidance (see next points).\n* There is a clear effort to justify the choice for heuristics and hyperparametrizations, but the efforts lack clarity both in substance and presentation (see notes on clarity) and the claim that they are \"theoretically supported\" is in many cases not true: many crucial aspects are resolved through trial-and-error (see e.g. end of page 6 and Appendix 7). In many cases, I feel like an ablation study showing the contribution of the added components in an empirical way would be clearer and more compelling.\n* Even the more analytical hyperparameters don't give the impression of being \"easier\" to find. E.g. for \"eta\", Appendix A.3 shows that many factors must be taken into account in a non-automated way, and new architectures may require careful tuning. What if we e.g. have batchnorm instead of layernorm? How is the concept of \"range\" characterized? Will it hold under non-stationary, noisy and/or sparse gradients?\n* Regarding stability: While very promising, the experiments aren't comprehensive enough to convince that the proposed settings (theoretical or empirical) are not highly specific to the results reported, due to the amount of hyperparameters and tuning involved. One thing that could help with this is to analyze the loss landscape stability (see AdamW paper), and/or extend experiments to other tasks and architectures.\n* Regarding experiments, it is unclear how many settings were tried before finding the reported Amos hyperparametrizations. This makes difficult to compare the different optimizers in terms of their hyperparametrization budgets. Furthermore, error bars are not provided: they would be welcome (together with a more publication-friendly plotting mechanism), although the differences between Amos and the rest are very significant.\n\nA couple of thoughts regarding weight decay:\n* Please correct footnote in page 2: Loschilov&Hutter precisely mentions that L2 and weight decay are not equivalent for adaptive optimizers (beyond empirical success), the footnote seems to operate on the opposite idea.\n* We saw that decoupled weight decay helps overcoming convergence issues with Adam. Would re-introducing adaptive weight decay also re-introduce some of those issues?\n", "content.clarity,_quality,_novelty_and_reproducibility": "* Regarding novelty (see my notes from before): I think this is a really nice and promising idea, and it is well embedded in recent and relevant literature.\n\n* Regarding quality (see my notes from before): I think the execution of the idea is heuristic-heavy, and contains a substantial degree of arbitrariness and complexity that is not justified in a compelling way. Experiments are very promising, but in my opinion do not make up for this.\n\n* I had several clarity issues reading the paper, related to notation, formulation, experiments, paper structure and general model clarity:\n  * The explanation for obtaining eta is unclear to me (\"match input/output range\", \"not dominate\"). Concept of \"range\" and its importance is not introduced. It seems that it would depend on weight distribution as well?\n  * Model-oriented scale: overloading of variable W is confusing.\n  * Notation: the lack of distinction between scalar+global variables (eta, c) and per-partition scalars hinders clarity. Indexing partitions would help\n  * Gamma: It is unclear how this component \"makes trained weights empirically converge to eta_tilde\". If eta_tilde is the norm for the full model, how does gamma achieve this without using that global information?\n  * weight decay: Could be expressed in a clearer way. Why is it affected by the decay multiplier \"d\", while it also has its own decay factor \"c\"? The explanation in 4.2 introducing L2 doesn't seem to address this\n  * Section 4.2 aims to provide a \"heuristic derivation\", but it is very difficult to follow since it is not lemma-oriented. At many points, it is not clear what are we expecting to see, and how exactly the discussed equations are related to Amos. E.g. after equation 5: \"now recall that we are given eta such that...\": this was claimed, but I don't see in the paper where this is satisfied. In general, I found the section very confusing as presented. My suggestion would be to resort to a lemma-oriented structure, and whenever the derivations aren't possible or don't lead to watertight conclusions (e.g.  inequalities, broad assumptions), provide experiments that support the ideas presented (e.g. tight bounds), as done in Appendix A.5.\n  * Experimental benchmarks: What is the difference between pre-training and regular training when comparing the observed results? If we are expected to train afterwards, wouldn't the final result (including the training after pre-training) be the actual target to compare? Note that recent results on \"critical learning periods\" (e.g. Achille et al 19). show that issues with pre-training can affect final performance.\n\n* Regarding reproducibility: The paper contains a clear description of the steps to be computed. The experiments are based on well-known, public architectures and benchmarks. Quantitative results are provided, although without error bars. Resources required are high but not unreachable. For the missing details, the authors pledge to provide an open-source (JAX) implementation, upon publication. If that is the case and assuming no lucky seeds, reproducibility issues are expected to be minimal.", "content.summary_of_the_review": "My opinion is that this contribution clearly deserves attention from the community, but it needs more work: It presents an optimizer of increased complexity, involving a substantial amount (potentially arbitrary) heuristics. Experiments are very promising, but there are methodological concerns.\nThe paper would greatly benefit from improvements in clarity, both in formulation and presentation, especially given the increased amount of details needed to understand and tune this optimizer.\n\nFor those reasons I'm inclined to marginally reject, but I thank the authors for their contribution and encourage them to address/answer some of my points above in order to reconsider my evaluation. ", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zfodIZGVWW"}
{"id": "7YzRdPMyyb", "forum": "zfodIZGVWW", "replyto": "zfodIZGVWW", "invitation": "ICLR.cc/2023/Conference/Paper3198/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3198/Reviewer_f9Uo", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3198/Reviewer_f9Uo", "tcdate": 1666726348265, "tmdate": 1666726348265, "date": 1666726348265, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper proposes Amos, an adaptive optimization method for deep learning. It combines various aspects, most notably an adaptive weight decay term and a step size involving an expected scale of model parameters, informed by structural knowledge about the model being trained. It is evaluated in extensive experiments on pretraining Transfomer models.", "content.strength_and_weaknesses": "### Strengths\n\n1. Improving optimization algorithms and/or estimating their hyperparameters using structural knowledge of the model is a very promising research direction. To my knowledge, this is one of only a few papers that uses model characteristics to inform the optimization hyperparameters (beyond layer-wise normalization and/or step sizes).\n\n2. The experiments on Transformers are extensive and consistently demonstrate significant improvements over state-of-the-art competitors. Given the importance and immense cost of such training tasks, that is a very significant improvement.\n\n### Weaknesses\n\n1. My main criticism is that the method combines a large number of aspects without proper ablations. If a method gives very good results, but we can't pin down which innovation really drives that improvement, the scientific value is greatly diminished. Comparing Eq. (1) to Adam or RMSProp, I can see at least 6 components/innovations that could be seen as largely independent and I would like to see investigated in isolation\n    - The factored learning rate involving the \"model-oriented scale\"\n    - The learning rate in front of the weight decay term being the square of the learning rate scaling the gradient ($\\xi^2 / \\hat{v}_t$ vs $\\xi/\\sqrt{\\hat{v}_t}$)\n    - The multiplier $M_2(g_t)$ in front of the weight decay term.\n    - The decay scheme for the global step size ($d_t$)\n    - The additional decay scheme for the weight decay term ($c_t$)\n    - Computing $\\hat{v}_t$ across model parameters instead of using running averages.\n\n2. The derivation of Amos is a series of approximations (some very crude) and heuristics/intuition. I could put some caveats on almost all the steps of the derivation. While the authors clearly state that this is a heuristic derivation, at some point we have to ask ourselves whether such a derivation is helpful or just obfuscates. Some steps that I found particularly problematic:\n    - Equation (6) suggests a particular _ratio_ of $\\alpha_t^2$ to $\\rho_t$. It is completely unclear to me how that should motivate $\\rho_t \\propto M_2(g_t)^2 / \\mathbf{E}[M_2(g_t)^2]$ and $\\alpha_t \\propto 1/\\sqrt{\\mathbf{E}[M_2[g_t]^2]]}$. This choice satisfies Eq. (6), but so does an infinite number of other choices.\n    - Assumption 1: This assumes $\\mathbf{E}[\\Vert g_t\\Vert^2] \\leq C \\cdot \\Vert \\mathbf{E}[g_t]\\Vert^2$, i.e., the variance of a stochastic gradient needs to go to zero as the true (expected) gradient goes to zero. That is the so-called interpolation regime: every data point is fit perfectly. This seems unlikely to be fulfilled in LLM pretraining tasks.\n    - Interpretation of $\\xi$. Sorry, but this is almost absurd. First, if we assume the per-example gradients to come from a zero-mean distribution this would imply $\\mathbf{E}[g_t] = 0$, in direct contradiction to the Equation below. Second, why should  $$\\left(\\frac{1}{N} \\sum_{i=1}^N x_i \\right)^2 = \\frac{1}{N^2}\\sum_{i=1}^N x_i^2$$ hold? That is simply not true and is not a meaningful approximation in any way. Third, the law of large numbers is completely irrelevant here.\n\n3. The experiments focus entirely on Transformer architectures. While this is certainly a model class of great practical importance, I would find it highly desirable to check the extent to which these findings transfer to other families of architectures and data modalities. Given the resources that went into the experiments involving Transformers, it would be \"cheap\" to throw in a ResNet on CIFAR-10/CIFAR-100/ImageNet. If Amos performs amicably there - great. If not, this would alert us of the fact that some of the proposed heuristics are specific to Transformers (which would be perfectly fine).", "content.clarity,_quality,_novelty_and_reproducibility": "**Quality:** While the method achieves very convincing experimental results, the _scientific_ quality of the paper is subpar in my opinion. The heuristic derivation involves so many approximations, heuristics, and \"intuitive arguments\" that I found it more confusing and obfuscating than helpful. Some of my specific concerns are listed above (weakness 2). Even more importantly, the method combines various, largely independent, innovations and it is entirely unclear to me, which of these actually contribute to the experimental success (weakness 1). In terms of experiments, the investigation on Transformers is extensive, but I would have expected to see experiments involving, e.g., ResNets on some vision data, for breadth (weakness 3)\n\n**Clarity:** The paper is generally well-written. Some of the steps in the derivation are not well-motivated in my opinion (weakness 2).\n\n**Originality:** The method proposes several innovations compared to Adam that are definitely novel. I think the general direction of using structural knowledge about the model (here: expected scales of the optimal weights) is a very promising yet under-explored.", "content.summary_of_the_review": "I list several scientific shortcomings above, which are think are pretty fundamental. In light of that, the good experimental results for the proposed method on their own do not warrant acceptance in my opinion.", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "3: reject, not good enough", "paper_forum": "zfodIZGVWW"}
{"id": "7V-WrBk7Ha", "forum": "zfodIZGVWW", "replyto": "zfodIZGVWW", "invitation": "ICLR.cc/2023/Conference/Paper3198/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper3198/Reviewer_Fga8", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper3198/Reviewer_Fga8", "tcdate": 1666620694213, "tmdate": 1666620736425, "date": 1666620694213, "content.confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.", "content.summary_of_the_paper": "The submission presents a new optimizer, Amos, which can heuristically determine the initial learning rate and adjust its decaying schedules for LR and L2 regularizer during training. The experiments show that Amos converges faster than AdamW on language models.", "content.strength_and_weaknesses": "#### Strength\n- The proposed optimizer can adaptively choose the decaying schedules for learning rate the L-2 regularize coefficient during training.\n- There are fewer sensitive hyper-parameters compared to the previous optimizers.\n\n#### Weaknesses\n-  Since the optimizer is not explicitly designed for the language model, the absent experimental results on other tasks, such as the vision or RL tasks, degenerate the contribution of this optimizer.\n- Some typos, e.g., step one in Algorithm 1, in which the $g_t$ should be bold. The bold and normal formats are used at will in the $\\alpha_t$ below Eq.(2).\n- Actually, $\\hat{v}_t$ is not nearly equal to $E[M_2(g_t)^2]$. In general, we have $$(\\hat{v}_t - E[M_2(g_t)^2])^2 \\leq \\beta (\\hat{v}_t - E[M_2(g_{t-1})^2])^2 + \\frac{\\beta^2}{1-\\beta}(E[M_2(g_t)^2] - E[M_2(g_{t-1})^2])^2$$ (see [1], Lemma 2), which is large until convergence. Hence it is strange to replace  $\\hat{v}_t$ with $E[M_2(g_t)^2]$.\n- The approximation in Eq.(4) is confusing. Since $\\alpha_t g_t$ can be small when we are close to convergence, but $\\rho_t \\theta_t$ is not. We can not ignore $\\rho_t \\theta_t$ directly.\n- Why $\\rho_t $  should be normalized by $E[M_2(g_t)^2]$? The stated reason ``the L2-regularizer should (on average) not depend on the norm of $g_t$'' seems weak and not solid.\n- Lack the comparison to some strong baselines, such as LAMB and Adam's variants.\n\n\n[1] Stochastic compositional gradient descent: algorithms for minimizing compositions of expected-value functions.", "content.clarity,_quality,_novelty_and_reproducibility": "The wring and presentation is not good, and there are too many heuristic derivations without further details. However, if all the heuristic parts are right, the novelty is enough. Since how to adaptively adjust the LR and weight decay with theoretical guarantee remains open.", "content.summary_of_the_review": "Due to the missing (1) experimental results on general tasks, (2) lack of convergence guarantee, and (3) too many confusing mathematic details in derivations, currently, I hold a negative score on the paper.", "content.correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zfodIZGVWW"}
{"id": "xP_d7SQdntd", "forum": "zgVDqw9ZUES", "replyto": "zgVDqw9ZUES", "invitation": "ICLR.cc/2023/Conference/Paper5681/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper5681/Reviewer_1g2Y", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper5681/Reviewer_1g2Y", "tcdate": 1666680380089, "tmdate": 1666680744217, "date": 1666680380089, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "This paper studies two infinite-width limits (kernel and feature learning limits) of fully-connected neural networks (MLPs) under adaptive gradient-based optimization. Both results generalize that of MLPs trained by a non-adaptive way. In addition, the authors modify a framework (called Tensor Program) that allows to express the adaptive gradient processing as well as the convergence guarantee.\n", "content.strength_and_weaknesses": "Strength:\n\n- This paper extends two infinite-width limits of MLPs for adaptive gradient-based optimization, which have not been studied before. The proposed results can generalize both kernel and feature learning limits of non-adaptive settings. It is interesting that the adaptive NTK regime is still data-independent like the non-adaptive NTK.  \n\n- They provide a general Tensor Program framework for the adaptive optimization setting with O(1/sqrt(n)) convergence rate guarantees. \n\nWeakness:\n\n- Adaptive optimizations have various benefits over the SGD (e.g., fast convergence, better generalization, etc). Can this point of view be captured by the proposed adaptive infinite-width limits? It would be great if more clear motivations and meaningful results of adaptive infinite-width limits are provided. \n\n- The paper focuses on simple settings (e.g., memoryless adaptive gradient descents, update of parameters in a single layer). But, it is unclear whether the proposed results hold for more general settings. \n", "content.clarity,_quality,_novelty_and_reproducibility": "The writing quality of this paper is quite poor and very informal. It should be improved by providing more comprehensive and rigorous flows. \n", "content.summary_of_the_review": "This paper extends infinite-width limits to the adaptive optimization setting, which has never been discovered before. But, it seems that a more in-depth comparison/analysis of the non-adaptive results would make the contributions much stronger. The writing quality needs to be improved for better readability.", "content.correctness": "4: All of the claims and statements are well-supported and correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "5: marginally below the acceptance threshold", "paper_forum": "zgVDqw9ZUES"}
{"id": "QEyOx16ag9", "forum": "zgVDqw9ZUES", "replyto": "zgVDqw9ZUES", "invitation": "ICLR.cc/2023/Conference/Paper5681/-/Official_Review", "signatures": "ICLR.cc/2023/Conference/Paper5681/Reviewer_k9hR", "readers": "everyone", "writers": "ICLR.cc/2023/Conference,ICLR.cc/2023/Conference/Paper5681/Reviewer_k9hR", "tcdate": 1666632490997, "tmdate": 1668197602158, "date": 1666632490997, "content.confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.", "content.summary_of_the_paper": "In this work the authors tackle the question of the infinite-width limit of neural networks trained using adaptive optimizers (like ADAM). They show that if the step taken in the optimizer depends on a non-linear, scale-invariant function of the previous step, then the NTK can be computed by applying said function to $\\frac{\\partial f_{train}}{\\partial\\theta}\\nabla_{\\theta}\\mathcal{L}_{train} $, and then multiplying by $\\frac{\\partial f_{out}}{\\partial\\theta}$. An analogous result holds for the $\\mu$-parameterization (the unique family of infinite-width feature learning initializations).", "content.strength_and_weaknesses": "The arguments for the memoryless case are very clean. In addition, these additions to the TP framework make it more flexible and can give insight in many of the more complex practical cases which arise when training large models. The authors make a good mix of intuition-building arguments and links to the more rigorous ones.\n\nOne point of clarification: in the mean-field limit, does $\\epsilon$ have to go to $0$ to get all the scaling arguments right? Is there an intuitive reason that this doesn't mess up the Gaussianity arguments via divisors which are random variables which can have significant probability mass around $0$? The final limits seem to be $\\epsilon$-independent.\n\nOne of the big weaknesses is that the promise of extending the analysis to the case of an adaptive optimizer with memory (depending on gradients $g$ further back in time) is not clearly made. I believe without that, the result in the memoryless case is interesting but not sufficiently significant for an acceptance rating. It would also be good to have a discussion on how the total time $t$ must scale with $n$ for the arguments to hold.\n\nI think the paper would be significantly strengthened if there was an explicit formulation and proof of at least the NTK for the ADAM algorithm. From the comments in the paper these seem like results that are already completed, or easily derivable for the framework. This paper is positioned to become a standard reference for NTK/$\\mu$-parameterization for adaptive algorithms, and it would be strange for the most popular adaptive algorithm to not be explicitly covered.\n\nDue to the limits of my technical ability and the review timescale, I have not been able to rigorously check the main proofs in the TP framework. I followed along with the arguments in the main text and they seem sound. I believe that there needs to be numerical evidence that the proposed scaling limits hold - not to replace the proofs, but to supplement them and decrease the possibility that some key point in the complex machinery did not go awry.\n\nAs a small note, on page 3 it is unclear why the labeling of the gradients $g$ has even time indices only.\n\nUpdate: most of the concerns above have been addressed; my updated review score reflects those changes.", "content.clarity,_quality,_novelty_and_reproducibility": "Sections 1-4 are very clear and easy to read. Sections 5 and 6 are more difficult; however, I believe that this is due to the technical nature of the content, and not any fault of the authors who make an effort to build intuition for the proofs. The arguments are, to my knowledge, novel.", "content.summary_of_the_review": "The paper does an excellent job of building intuitive and rigorous arguments for memoryless adaptive optimizers. However, I feel that this is not a significant enough contribution on its own, and the case of non-memoryless optimizers like ADAM should be explicitly covered if they are in fact trivial extensions of the framework as suggested by the authors. I did not have the time nor expertise to rigorously check the proofs. I also suggest that numerical evidence of convergence to the theoretical limits would be very helpful to readers, especially those without strong theoretical backgrounds.", "content.correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.", "content.technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.", "content.empirical_novelty_and_significance": "Not applicable", "content.flag_for_ethics_review": "[\"NO.\"]", "content.recommendation": "8: accept, good paper", "paper_forum": "zgVDqw9ZUES"}
